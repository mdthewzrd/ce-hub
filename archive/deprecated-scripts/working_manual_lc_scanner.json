{
  "start_date": "2025-11-10",
  "end_date": "2025-11-13",
  "use_real_scan": true,
  "scanner_type": "uploaded",
  "uploaded_code": "import pandas as pd\nimport aiohttp\nimport asyncio\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Configuration - PRESERVED PARAMETER INTEGRITY\nAPI_KEY = '4r6MZNWLy2ucmhVI7fY8MrvXfXTSmxpy'\nMAX_CONCURRENT = 3\n\n# LC Frontside D2 Extended 1 Parameters - EXACT VALUES FROM WORKING SCANNER\nHIGH_PCT_CHG_TIER1 = 1.0     # 100% move for $5-15 stocks\nHIGH_PCT_CHG_TIER2 = 0.5     # 50% move for $15-25 stocks  \nHIGH_PCT_CHG_TIER3 = 0.3     # 30% move for $25-50 stocks\nHIGH_PCT_CHG_TIER4 = 0.2     # 20% move for $50-90 stocks\nHIGH_PCT_CHG_TIER5 = 0.15    # 15% move for $90+ stocks\n\nDIST_THRESHOLD_TIER1 = 2.5   # Distance threshold for tier 1\nDIST_THRESHOLD_TIER2 = 2.0   # Distance threshold for tier 2\nDIST_THRESHOLD_TIER3 = 1.5   # Distance threshold for tier 3\nDIST_THRESHOLD_TIER4 = 1.0   # Distance threshold for tier 4\nDIST_THRESHOLD_TIER5 = 0.75  # Distance threshold for tier 5\n\nHIGH_CHG_ATR_MIN = 1.5       # Minimum ATR expansion\nDIST_9EMA_ATR_MIN = 2.0      # Distance from 9 EMA in ATR\nDIST_20EMA_ATR_MIN = 3.0     # Distance from 20 EMA in ATR\nVOLUME_MIN = 10000000        # 10M minimum volume\nDOLLAR_VOL_MIN = 500000000   # 500M minimum dollar volume\nPRICE_MIN = 5.0              # $5 minimum price\n\ndef compute_indicators(df):\n    \"\"\"Compute LC indicators with preserved parameter integrity\"\"\"\n    print(f\"Computing indicators for {len(df)} records...\")\n    \n    # Sort by ticker and date for proper time series\n    df = df.sort_values(by=['ticker', 'date'])\n    \n    # Previous day close\n    df['pdc'] = df.groupby('ticker')['c'].shift(1)\n    \n    # ATR calculation - 14 period rolling\n    df['high_low'] = df['h'] - df['l']\n    df['high_pdc'] = (df['h'] - df['pdc']).abs()\n    df['low_pdc'] = (df['l'] - df['pdc']).abs()\n    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)\n    df['atr'] = df.groupby('ticker')['true_range'].transform(lambda x: x.rolling(window=14).mean())\n    \n    # Shifted values for yesterday comparison\n    df['h1'] = df.groupby('ticker')['h'].shift(1)\n    df['l1'] = df.groupby('ticker')['l'].shift(1)\n    \n    # High percentage change from previous close\n    df['high_pct_chg'] = (df['h'] / df['pdc']) - 1.0\n    \n    # ATR normalized high change\n    df['high_chg_atr'] = (df['h'] - df['o']) / df['atr']\n    \n    # EMAs\n    df['ema9'] = df.groupby('ticker')['c'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n    df['ema20'] = df.groupby('ticker')['c'].transform(lambda x: x.ewm(span=20, adjust=False).mean())\n    df['ema50'] = df.groupby('ticker')['c'].transform(lambda x: x.ewm(span=50, adjust=False).mean())\n    \n    # EMA distances in ATR terms\n    df['dist_h_9ema_atr'] = (df['h'] - df['ema9']) / df['atr']\n    df['dist_h_20ema_atr'] = (df['h'] - df['ema20']) / df['atr']\n    \n    # Rolling highs for breakout detection\n    df['highest_high_20'] = df.groupby('ticker')['h'].transform(lambda x: x.rolling(window=20, min_periods=1).max())\n    \n    # Distance calculation for price tiers\n    df['highest_high_5'] = df.groupby('ticker')['h'].transform(lambda x: x.rolling(window=5, min_periods=1).max())\n    df['lowest_low_20'] = df.groupby('ticker')['l'].transform(lambda x: x.rolling(window=20, min_periods=1).min())\n    df['highest_high_5_1'] = df.groupby('ticker')['highest_high_5'].shift(1)\n    df['lowest_low_20_1'] = df.groupby('ticker')['lowest_low_20'].shift(1)\n    df['highest_high_5_dist_to_lowest_low_20_pct_1'] = (df['highest_high_5_1'] / df['lowest_low_20_1']) - 1.0\n    \n    # Dollar volume\n    df['dol_v'] = df['c'] * df['v']\n    \n    print(f\"‚úÖ Indicators computed\")\n    return df\n\ndef apply_lc_frontside_d2_extended_1_pattern(df):\n    \"\"\"Apply LC Frontside D2 Extended 1 pattern - EXACT LOGIC FROM WORKING SCANNER\"\"\"\n    print(\"Applying LC Frontside D2 Extended 1 pattern...\")\n    \n    # Remove rows without sufficient data\n    required_cols = ['atr', 'pdc', 'h1', 'l1', 'ema9', 'ema20', 'ema50']\n    df_clean = df.dropna(subset=required_cols)\n    \n    print(f\"After removing NaN: {len(df_clean)} records\")\n    \n    if df_clean.empty:\n        return []\n    \n    # LC Frontside D2 Extended 1 Pattern - PRESERVED EXACT LOGIC\n    price_tier_conditions = (\n        # Tier 1: $5-15 stocks need 100% move\n        ((df_clean['high_pct_chg'] >= HIGH_PCT_CHG_TIER1) & \n         (df_clean['c_ua'] >= 5.0) & (df_clean['c_ua'] < 15.0) & \n         (df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'] >= DIST_THRESHOLD_TIER1)) |\n        \n        # Tier 2: $15-25 stocks need 50% move\n        ((df_clean['high_pct_chg'] >= HIGH_PCT_CHG_TIER2) & \n         (df_clean['c_ua'] >= 15.0) & (df_clean['c_ua'] < 25.0) & \n         (df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'] >= DIST_THRESHOLD_TIER2)) |\n        \n        # Tier 3: $25-50 stocks need 30% move\n        ((df_clean['high_pct_chg'] >= HIGH_PCT_CHG_TIER3) & \n         (df_clean['c_ua'] >= 25.0) & (df_clean['c_ua'] < 50.0) & \n         (df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'] >= DIST_THRESHOLD_TIER3)) |\n        \n        # Tier 4: $50-90 stocks need 20% move\n        ((df_clean['high_pct_chg'] >= HIGH_PCT_CHG_TIER4) & \n         (df_clean['c_ua'] >= 50.0) & (df_clean['c_ua'] < 90.0) & \n         (df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'] >= DIST_THRESHOLD_TIER4)) |\n        \n        # Tier 5: $90+ stocks need 15% move\n        ((df_clean['high_pct_chg'] >= HIGH_PCT_CHG_TIER5) & \n         (df_clean['c_ua'] >= 90.0) & \n         (df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'] >= DIST_THRESHOLD_TIER5))\n    )\n    \n    df_clean['lc_frontside_d2_extended_1'] = (\n        # Basic higher highs and lows\n        (df_clean['h'] >= df_clean['h1']) &\n        (df_clean['l'] >= df_clean['l1']) &\n        \n        # Price tier conditions (preserved exact logic)\n        price_tier_conditions &\n        \n        # ATR expansion requirement\n        (df_clean['high_chg_atr'] >= HIGH_CHG_ATR_MIN) &\n        \n        # Green day requirement\n        (df_clean['c'] >= df_clean['o']) &\n        \n        # EMA distance requirements\n        (df_clean['dist_h_9ema_atr'] >= DIST_9EMA_ATR_MIN) &\n        (df_clean['dist_h_20ema_atr'] >= DIST_20EMA_ATR_MIN) &\n        \n        # Volume requirements\n        (df_clean['v_ua'] >= VOLUME_MIN) &\n        (df_clean['dol_v'] >= DOLLAR_VOL_MIN) &\n        \n        # Price minimum\n        (df_clean['c_ua'] >= PRICE_MIN) &\n        \n        # New highs and trend requirements\n        (df_clean['h'] >= df_clean['highest_high_20']) &\n        (df_clean['ema9'] >= df_clean['ema20']) &\n        (df_clean['ema20'] >= df_clean['ema50'])\n    ).astype(int)\n    \n    # Filter to pattern matches\n    lc_results = df_clean[df_clean['lc_frontside_d2_extended_1'] == 1].copy()\n    \n    print(f\"‚úÖ Found {len(lc_results)} LC Frontside D2 Extended 1 patterns\")\n    \n    # Return as list for API\n    results = []\n    for _, row in lc_results.iterrows():\n        results.append({\n            'ticker': row['ticker'],\n            'date': str(row['date']),\n            'gap_pct': float(row.get('high_pct_chg', 0.0)),\n            'parabolic_score': 90.0,  # High score for LC D2 Extended 1\n            'lc_frontside_d2_extended_1': 1,\n            'volume': int(row['v']),\n            'close': float(row['c']),\n            'confidence_score': 98.0  # Very high confidence for manual scanner\n        })\n    \n    return results\n\nasync def fetch_daily_data(session, date, adj, semaphore):\n    \"\"\"Fetch daily stock data\"\"\"\n    async with semaphore:\n        url = f\"https://api.polygon.io/v2/aggs/grouped/locale/us/market/stocks/{date}?adjusted={adj}&apiKey={API_KEY}\"\n        try:\n            async with session.get(url) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    if 'results' in data and data['results']:\n                        df = pd.DataFrame(data['results'])\n                        df['date'] = pd.to_datetime(df['t'], unit='ms').dt.date\n                        df.rename(columns={'T': 'ticker'}, inplace=True)\n                        print(f\"‚úÖ {date}: {len(df)} stocks\")\n                        return df\n                else:\n                    print(f\"‚ùå {date}: API error {response.status}\")\n            return pd.DataFrame()\n        except Exception as e:\n            print(f\"‚ùå {date}: {e}\")\n            return pd.DataFrame()\n\nasync def main():\n    \"\"\"Main LC Frontside D2 Extended 1 scanner function\"\"\"\n    print(\"üöÄ LC Frontside D2 Extended 1 Scanner - Manual Split Version\")\n    \n    # Get recent trading days for analysis\n    end_date = datetime.now().date()\n    dates = [(end_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(5, 0, -1)]\n    \n    semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n    all_data_adj = []\n    all_data_unadj = []\n    \n    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n        print(f\"Fetching adjusted data for {len(dates)} days...\")\n        tasks = [fetch_daily_data(session, date, \"true\", semaphore) for date in dates]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        for result in results:\n            if isinstance(result, pd.DataFrame) and not result.empty:\n                all_data_adj.append(result)\n        \n        print(f\"Fetching unadjusted data for {len(dates)} days...\")\n        tasks = [fetch_daily_data(session, date, \"false\", semaphore) for date in dates]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        for result in results:\n            if isinstance(result, pd.DataFrame) and not result.empty:\n                # Add _ua suffix for unadjusted\n                result = result.rename(columns={\n                    col: col + '_ua' if col not in ['date', 'ticker'] else col\n                    for col in result.columns\n                })\n                all_data_unadj.append(result)\n    \n    if not all_data_adj or not all_data_unadj:\n        print(\"‚ùå No data fetched\")\n        return []\n    \n    # Combine adjusted and unadjusted data\n    df_adj = pd.concat(all_data_adj, ignore_index=True)\n    df_unadj = pd.concat(all_data_unadj, ignore_index=True)\n    df_combined = pd.merge(df_adj, df_unadj, on=['date', 'ticker'], how='inner')\n    \n    print(f\"‚úÖ Combined: {len(df_combined)} records\")\n    \n    # Compute indicators\n    df_with_indicators = compute_indicators(df_combined)\n    \n    # Apply LC Frontside D2 Extended 1 pattern\n    results = apply_lc_frontside_d2_extended_1_pattern(df_with_indicators)\n    \n    print(f\"üéâ LC Frontside D2 Extended 1 scanner found {len(results)} results!\")\n    return results\n\n# Entry point for backend execution\nif __name__ == \"__main__\":\n    import asyncio\n    results = asyncio.run(main())\n    print(f\"Final LC D2 Extended 1 results: {len(results)} patterns found\")"
}