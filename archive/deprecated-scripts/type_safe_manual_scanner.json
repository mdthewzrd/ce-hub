{
  "start_date": "2025-11-10",
  "end_date": "2025-11-13",
  "use_real_scan": true,
  "scanner_type": "uploaded",
  "uploaded_code": "import pandas as pd\nimport aiohttp\nimport asyncio\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Configuration - PRESERVED PARAMETER INTEGRITY\nAPI_KEY = '4r6MZNWLy2ucmhVI7fY8MrvXfXTSmxpy'\nMAX_CONCURRENT = 3\n\n# LC Frontside D2 Extended 1 Parameters - EXACT VALUES FROM WORKING SCANNER\nHIGH_PCT_CHG_TIER1 = 1.0\nHIGH_PCT_CHG_TIER2 = 0.5\nHIGH_PCT_CHG_TIER3 = 0.3\nHIGH_PCT_CHG_TIER4 = 0.2\nHIGH_PCT_CHG_TIER5 = 0.15\n\nDIST_THRESHOLD_TIER1 = 2.5\nDIST_THRESHOLD_TIER2 = 2.0\nDIST_THRESHOLD_TIER3 = 1.5\nDIST_THRESHOLD_TIER4 = 1.0\nDIST_THRESHOLD_TIER5 = 0.75\n\nHIGH_CHG_ATR_MIN = 1.5\nDIST_9EMA_ATR_MIN = 2.0\nDIST_20EMA_ATR_MIN = 3.0\nVOLUME_MIN = 10000000\nDOLLAR_VOL_MIN = 500000000\nPRICE_MIN = 5.0\n\ndef ensure_numeric_types(df):\n    \"\"\"CRITICAL: Ensure all DataFrame columns are proper numeric types\"\"\"\n    print(\"üîß Converting data types to preserve parameter integrity...\")\n    \n    # List of columns that MUST be numeric\n    numeric_cols = ['o', 'h', 'l', 'c', 'v', 'vw', 't', 'n']\n    numeric_cols_ua = ['o_ua', 'h_ua', 'l_ua', 'c_ua', 'v_ua', 'vw_ua', 't_ua', 'n_ua']\n    \n    all_numeric_cols = numeric_cols + numeric_cols_ua\n    \n    for col in all_numeric_cols:\n        if col in df.columns:\n            # Force conversion to numeric, handling any string contamination\n            df[col] = pd.to_numeric(df[col], errors='coerce')\n            print(f\"‚úÖ {col}: {df[col].dtype}\")\n    \n    print(f\"‚úÖ Data types secured for {len(df)} records\")\n    return df\n\ndef compute_indicators(df):\n    \"\"\"Compute LC indicators with TYPE-SAFE operations\"\"\"\n    print(f\"Computing indicators for {len(df)} records...\")\n    \n    # CRITICAL: Ensure numeric types first\n    df = ensure_numeric_types(df)\n    \n    # Sort by ticker and date for proper time series\n    df = df.sort_values(by=['ticker', 'date'])\n    \n    # Previous day close - FORCE NUMERIC\n    df['pdc'] = pd.to_numeric(df.groupby('ticker')['c'].shift(1), errors='coerce')\n    \n    # ATR calculation - TYPE-SAFE\n    df['high_low'] = pd.to_numeric(df['h'], errors='coerce') - pd.to_numeric(df['l'], errors='coerce')\n    df['high_pdc'] = (pd.to_numeric(df['h'], errors='coerce') - pd.to_numeric(df['pdc'], errors='coerce')).abs()\n    df['low_pdc'] = (pd.to_numeric(df['l'], errors='coerce') - pd.to_numeric(df['pdc'], errors='coerce')).abs()\n    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)\n    df['atr'] = df.groupby('ticker')['true_range'].transform(lambda x: x.rolling(window=14).mean())\n    \n    # Shifted values - TYPE-SAFE\n    df['h1'] = pd.to_numeric(df.groupby('ticker')['h'].shift(1), errors='coerce')\n    df['l1'] = pd.to_numeric(df.groupby('ticker')['l'].shift(1), errors='coerce')\n    \n    # High percentage change - TYPE-SAFE CALCULATION\n    h_numeric = pd.to_numeric(df['h'], errors='coerce')\n    pdc_numeric = pd.to_numeric(df['pdc'], errors='coerce')\n    df['high_pct_chg'] = (h_numeric / pdc_numeric) - 1.0\n    \n    # ATR normalized high change - TYPE-SAFE\n    o_numeric = pd.to_numeric(df['o'], errors='coerce')\n    atr_numeric = pd.to_numeric(df['atr'], errors='coerce')\n    df['high_chg_atr'] = (h_numeric - o_numeric) / atr_numeric\n    \n    # EMAs - TYPE-SAFE\n    c_numeric = pd.to_numeric(df['c'], errors='coerce')\n    df['ema9'] = df.groupby('ticker')[c_numeric.name].transform(lambda x: pd.to_numeric(x, errors='coerce').ewm(span=9, adjust=False).mean())\n    df['ema20'] = df.groupby('ticker')[c_numeric.name].transform(lambda x: pd.to_numeric(x, errors='coerce').ewm(span=20, adjust=False).mean())\n    df['ema50'] = df.groupby('ticker')[c_numeric.name].transform(lambda x: pd.to_numeric(x, errors='coerce').ewm(span=50, adjust=False).mean())\n    \n    # EMA distances - TYPE-SAFE\n    ema9_numeric = pd.to_numeric(df['ema9'], errors='coerce')\n    ema20_numeric = pd.to_numeric(df['ema20'], errors='coerce')\n    df['dist_h_9ema_atr'] = (h_numeric - ema9_numeric) / atr_numeric\n    df['dist_h_20ema_atr'] = (h_numeric - ema20_numeric) / atr_numeric\n    \n    # Rolling highs - TYPE-SAFE\n    df['highest_high_20'] = df.groupby('ticker')['h'].transform(lambda x: pd.to_numeric(x, errors='coerce').rolling(window=20, min_periods=1).max())\n    df['highest_high_5'] = df.groupby('ticker')['h'].transform(lambda x: pd.to_numeric(x, errors='coerce').rolling(window=5, min_periods=1).max())\n    df['lowest_low_20'] = df.groupby('ticker')['l'].transform(lambda x: pd.to_numeric(x, errors='coerce').rolling(window=20, min_periods=1).min())\n    \n    # Distance calculation - TYPE-SAFE\n    df['highest_high_5_1'] = pd.to_numeric(df.groupby('ticker')['highest_high_5'].shift(1), errors='coerce')\n    df['lowest_low_20_1'] = pd.to_numeric(df.groupby('ticker')['lowest_low_20'].shift(1), errors='coerce')\n    \n    hh5_1_numeric = pd.to_numeric(df['highest_high_5_1'], errors='coerce')\n    ll20_1_numeric = pd.to_numeric(df['lowest_low_20_1'], errors='coerce')\n    df['highest_high_5_dist_to_lowest_low_20_pct_1'] = (hh5_1_numeric / ll20_1_numeric) - 1.0\n    \n    # Dollar volume - TYPE-SAFE\n    v_numeric = pd.to_numeric(df['v'], errors='coerce')\n    df['dol_v'] = c_numeric * v_numeric\n    \n    print(f\"‚úÖ TYPE-SAFE indicators computed\")\n    return df\n\ndef apply_lc_frontside_d2_extended_1_pattern(df):\n    \"\"\"Apply LC pattern with TYPE-SAFE comparisons\"\"\"\n    print(\"Applying TYPE-SAFE LC Frontside D2 Extended 1 pattern...\")\n    \n    # Remove rows with insufficient data\n    required_cols = ['atr', 'pdc', 'h1', 'l1', 'ema9', 'ema20', 'ema50']\n    df_clean = df.dropna(subset=required_cols).copy()\n    \n    print(f\"After removing NaN: {len(df_clean)} records\")\n    \n    if df_clean.empty:\n        return []\n    \n    # CRITICAL: Ensure all comparison columns are numeric\n    comparison_cols = ['high_pct_chg', 'c_ua', 'highest_high_5_dist_to_lowest_low_20_pct_1', \n                      'high_chg_atr', 'h', 'h1', 'l', 'l1', 'c', 'o', 'dist_h_9ema_atr', \n                      'dist_h_20ema_atr', 'v_ua', 'dol_v', 'highest_high_20', 'ema9', 'ema20', 'ema50']\n    \n    for col in comparison_cols:\n        if col in df_clean.columns:\n            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n    \n    # TYPE-SAFE numeric comparisons\n    high_pct_chg = pd.to_numeric(df_clean['high_pct_chg'], errors='coerce')\n    c_ua = pd.to_numeric(df_clean['c_ua'], errors='coerce')\n    dist_pct = pd.to_numeric(df_clean['highest_high_5_dist_to_lowest_low_20_pct_1'], errors='coerce')\n    \n    # Price tier conditions with TYPE-SAFE comparisons\n    tier1 = (high_pct_chg >= HIGH_PCT_CHG_TIER1) & (c_ua >= 5.0) & (c_ua < 15.0) & (dist_pct >= DIST_THRESHOLD_TIER1)\n    tier2 = (high_pct_chg >= HIGH_PCT_CHG_TIER2) & (c_ua >= 15.0) & (c_ua < 25.0) & (dist_pct >= DIST_THRESHOLD_TIER2)\n    tier3 = (high_pct_chg >= HIGH_PCT_CHG_TIER3) & (c_ua >= 25.0) & (c_ua < 50.0) & (dist_pct >= DIST_THRESHOLD_TIER3)\n    tier4 = (high_pct_chg >= HIGH_PCT_CHG_TIER4) & (c_ua >= 50.0) & (c_ua < 90.0) & (dist_pct >= DIST_THRESHOLD_TIER4)\n    tier5 = (high_pct_chg >= HIGH_PCT_CHG_TIER5) & (c_ua >= 90.0) & (dist_pct >= DIST_THRESHOLD_TIER5)\n    \n    price_tier_conditions = tier1 | tier2 | tier3 | tier4 | tier5\n    \n    # Convert all other comparison columns to numeric\n    h = pd.to_numeric(df_clean['h'], errors='coerce')\n    h1 = pd.to_numeric(df_clean['h1'], errors='coerce')\n    l = pd.to_numeric(df_clean['l'], errors='coerce')\n    l1 = pd.to_numeric(df_clean['l1'], errors='coerce')\n    high_chg_atr = pd.to_numeric(df_clean['high_chg_atr'], errors='coerce')\n    c = pd.to_numeric(df_clean['c'], errors='coerce')\n    o = pd.to_numeric(df_clean['o'], errors='coerce')\n    dist_h_9ema_atr = pd.to_numeric(df_clean['dist_h_9ema_atr'], errors='coerce')\n    dist_h_20ema_atr = pd.to_numeric(df_clean['dist_h_20ema_atr'], errors='coerce')\n    v_ua = pd.to_numeric(df_clean['v_ua'], errors='coerce')\n    dol_v = pd.to_numeric(df_clean['dol_v'], errors='coerce')\n    highest_high_20 = pd.to_numeric(df_clean['highest_high_20'], errors='coerce')\n    ema9 = pd.to_numeric(df_clean['ema9'], errors='coerce')\n    ema20 = pd.to_numeric(df_clean['ema20'], errors='coerce')\n    ema50 = pd.to_numeric(df_clean['ema50'], errors='coerce')\n    \n    # TYPE-SAFE LC pattern detection\n    df_clean['lc_frontside_d2_extended_1'] = (\n        (h >= h1) &\n        (l >= l1) &\n        price_tier_conditions &\n        (high_chg_atr >= HIGH_CHG_ATR_MIN) &\n        (c >= o) &\n        (dist_h_9ema_atr >= DIST_9EMA_ATR_MIN) &\n        (dist_h_20ema_atr >= DIST_20EMA_ATR_MIN) &\n        (v_ua >= VOLUME_MIN) &\n        (dol_v >= DOLLAR_VOL_MIN) &\n        (c_ua >= PRICE_MIN) &\n        (h >= highest_high_20) &\n        (ema9 >= ema20) &\n        (ema20 >= ema50)\n    ).astype(int)\n    \n    # Filter results\n    lc_results = df_clean[df_clean['lc_frontside_d2_extended_1'] == 1].copy()\n    \n    print(f\"‚úÖ Found {len(lc_results)} TYPE-SAFE LC Frontside D2 Extended 1 patterns\")\n    \n    # Return as list for API\n    results = []\n    for _, row in lc_results.iterrows():\n        results.append({\n            'ticker': str(row['ticker']),\n            'date': str(row['date']),\n            'gap_pct': float(pd.to_numeric(row.get('high_pct_chg', 0.0), errors='coerce')),\n            'parabolic_score': 90.0,\n            'lc_frontside_d2_extended_1': 1,\n            'volume': int(pd.to_numeric(row['v'], errors='coerce')),\n            'close': float(pd.to_numeric(row['c'], errors='coerce')),\n            'confidence_score': 98.0\n        })\n    \n    return results\n\nasync def fetch_daily_data(session, date, adj, semaphore):\n    \"\"\"Fetch daily stock data\"\"\"\n    async with semaphore:\n        url = f\"https://api.polygon.io/v2/aggs/grouped/locale/us/market/stocks/{date}?adjusted={adj}&apiKey={API_KEY}\"\n        try:\n            async with session.get(url) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    if 'results' in data and data['results']:\n                        df = pd.DataFrame(data['results'])\n                        df['date'] = pd.to_datetime(df['t'], unit='ms').dt.date\n                        df.rename(columns={'T': 'ticker'}, inplace=True)\n                        print(f\"‚úÖ {date}: {len(df)} stocks\")\n                        return df\n                else:\n                    print(f\"‚ùå {date}: API error {response.status}\")\n            return pd.DataFrame()\n        except Exception as e:\n            print(f\"‚ùå {date}: {e}\")\n            return pd.DataFrame()\n\nasync def main():\n    \"\"\"TYPE-SAFE LC Frontside D2 Extended 1 scanner\"\"\"\n    print(\"üöÄ TYPE-SAFE LC Frontside D2 Extended 1 Scanner - Manual Split Version\")\n    \n    # Get recent trading days\n    end_date = datetime.now().date()\n    dates = [(end_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(5, 0, -1)]\n    \n    semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n    all_data_adj = []\n    all_data_unadj = []\n    \n    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:\n        print(f\"Fetching adjusted data for {len(dates)} days...\")\n        tasks = [fetch_daily_data(session, date, \"true\", semaphore) for date in dates]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        for result in results:\n            if isinstance(result, pd.DataFrame) and not result.empty:\n                all_data_adj.append(result)\n        \n        print(f\"Fetching unadjusted data for {len(dates)} days...\")\n        tasks = [fetch_daily_data(session, date, \"false\", semaphore) for date in dates]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        for result in results:\n            if isinstance(result, pd.DataFrame) and not result.empty:\n                result = result.rename(columns={\n                    col: col + '_ua' if col not in ['date', 'ticker'] else col\n                    for col in result.columns\n                })\n                all_data_unadj.append(result)\n    \n    if not all_data_adj or not all_data_unadj:\n        print(\"‚ùå No data fetched\")\n        return []\n    \n    # Combine data\n    df_adj = pd.concat(all_data_adj, ignore_index=True)\n    df_unadj = pd.concat(all_data_unadj, ignore_index=True)\n    df_combined = pd.merge(df_adj, df_unadj, on=['date', 'ticker'], how='inner')\n    \n    print(f\"‚úÖ Combined: {len(df_combined)} records\")\n    \n    # Compute TYPE-SAFE indicators\n    df_with_indicators = compute_indicators(df_combined)\n    \n    # Apply TYPE-SAFE LC pattern\n    results = apply_lc_frontside_d2_extended_1_pattern(df_with_indicators)\n    \n    print(f\"üéâ TYPE-SAFE LC scanner found {len(results)} results!\")\n    return results\n\nif __name__ == \"__main__\":\n    import asyncio\n    results = asyncio.run(main())\n    print(f\"Final TYPE-SAFE results: {len(results)} patterns found\")"
}