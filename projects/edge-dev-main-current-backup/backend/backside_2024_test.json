{
  "scanner_type": "uploaded",
  "uploaded_code": "# Standardized Backside Para B Scanner\n# Compatible with Universal Scanner Engine\n# Original: /Users/michaeldurante/.anaconda/working code/backside daily para/backside para b.py\n\nimport pandas as pd\nimport numpy as np\nimport requests\nfrom datetime import datetime\nfrom typing import List, Dict, Any\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Global Config â”€â”€â”€â”€â”€â”€â”€â”€â”€\nsession = requests.Session()\nAPI_KEY = \"Fm7brz4s23eSocDErnL68cE7wspz2K1I\"\nBASE_URL = \"https://api.polygon.io\"\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Required by Universal Scanner Engine â”€â”€â”€â”€â”€â”€â”€â”€â”€\nSYMBOLS = [\n    'MSTR','SMCI','DJT','BABA','TCOM','AMC','SOXL','MRVL','TGT','DOCU','ZM','DIS',\n    'NFLX','SNAP','RBLX','META','SE','NVDA','AAPL','MSFT','GOOGL','AMZN','TSLA',\n    'AMD','INTC','BA','PYPL','QCOM','ORCL','KO','PEP','ABBV','JNJ','CRM','BAC',\n    'JPM','WMT','CVX','XOM','COP','RTX','SPGI','GS','HD','LOW','COST','UNH','NKE',\n    'LMT','HON','CAT','LIN','ADBE','AVGO','TXN','ACN','UPS','BLK','PM','ELV','VRTX',\n    'ZTS','NOW','ISRG','PLD','MS','MDT','WM','GE','IBM','BKNG','FDX','ADP','EQIX',\n    'DHR','SNPS','REGN','SYK','TMO','CVS','INTU','SCHW','CI','APD','SO','MMC','ICE',\n    'FIS','ADI','CSX','LRCX','GILD','RIVN','PLTR','SNOW','SPY','QQQ','IWM','RIOT',\n    'MARA','COIN','MRNA','CELH','UPST','AFRM','DKNG'\n]\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Original Scanner Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€\nP = {\n    # hard liquidity / price\n    \"price_min\"        : 8.0,\n    \"adv20_min_usd\"    : 30_000_000,\n\n    # backside context (absolute window)\n    \"abs_lookback_days\": 1000,\n    \"abs_exclude_days\" : 10,\n    \"pos_abs_max\"      : 0.75,\n\n    # trigger mold (evaluated on D-1 or D-2)\n    \"trigger_mode\"     : \"D1_or_D2\",   # \"D1_only\" or \"D1_or_D2\"\n    \"atr_mult\"         : .9,\n    \"vol_mult\"         : 0.9,         # max(D-1 vol/avg, D-2 vol/avg)\n\n    # Relative D-1 vol (optional). Set to None to disable.\n    \"d1_vol_mult_min\"  : None,         # e.g., 1.25\n\n    # NEW: Absolute D-1 volume floor (shares). Set None to disable.\n    \"d1_volume_min\"    : 15_000_000,   # e.g., require â‰¥ 20M shares on D-1\n\n    \"slope5d_min\"      : 3.0,\n    \"high_ema9_mult\"   : 1.05,\n\n    # trade-day (D0) gates\n    \"gap_div_atr_min\"   : .75,\n    \"open_over_ema9_min\": .9,\n    \"d1_green_atr_min\"  : 0.30,\n    \"require_open_gt_prev_high\": True,\n\n    # relative requirement\n    \"enforce_d1_above_d2\": True,\n}\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Original Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef fetch_daily(tkr: str, start: str, end: str) -> pd.DataFrame:\n    url = f\"{BASE_URL}/v2/aggs/ticker/{tkr}/range/1/day/{start}/{end}\"\n    r   = session.get(url, params={\"apiKey\": API_KEY, \"adjusted\":\"true\", \"sort\":\"asc\", \"limit\":50000})\n    r.raise_for_status()\n    rows = r.json().get(\"results\", [])\n    if not rows: return pd.DataFrame()\n    return (pd.DataFrame(rows)\n            .assign(Date=lambda d: pd.to_datetime(d[\"t\"], unit=\"ms\", utc=True))\n            .rename(columns={\"o\":\"Open\",\"h\":\"High\",\"l\":\"Low\",\"c\":\"Close\",\"v\":\"Volume\"})\n            .set_index(\"Date\")[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n            .sort_index())\n\ndef add_daily_metrics(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty: return df\n    m = df.copy()\n    try: m.index = m.index.tz_localize(None)\n    except Exception: pass\n\n    m[\"EMA_9\"]  = m[\"Close\"].ewm(span=9 , adjust=False).mean()\n    m[\"EMA_20\"] = m[\"Close\"].ewm(span=20, adjust=False).mean()\n\n    hi_lo   = m[\"High\"] - m[\"Low\"]\n    hi_prev = (m[\"High\"] - m[\"Close\"].shift(1)).abs()\n    lo_prev = (m[\"Low\"]  - m[\"Close\"].shift(1)).abs()\n    m[\"TR\"]      = pd.concat([hi_lo, hi_prev, lo_prev], axis=1).max(axis=1)\n    m[\"ATR_raw\"] = m[\"TR\"].rolling(14, min_periods=14).mean()\n    m[\"ATR\"]     = m[\"ATR_raw\"].shift(1)\n\n    m[\"VOL_AVG\"]     = m[\"Volume\"].rolling(14, min_periods=14).mean().shift(1)\n    m[\"Prev_Volume\"] = m[\"Volume\"].shift(1)\n    m[\"ADV20_$\"]     = (m[\"Close\"] * m[\"Volume\"]).rolling(20, min_periods=20).mean().shift(1)\n\n    m[\"Slope_9_5d\"]  = (m[\"EMA_9\"] - m[\"EMA_9\"].shift(5)) / m[\"EMA_9\"].shift(5) * 100\n    m[\"High_over_EMA9_div_ATR\"] = (m[\"High\"] - m[\"EMA_9\"]) / m[\"ATR\"]\n\n    m[\"Gap_abs\"]       = (m[\"Open\"] - m[\"Close\"].shift(1)).abs()\n    m[\"Gap_over_ATR\"]  = m[\"Gap_abs\"] / m[\"ATR\"]\n    m[\"Open_over_EMA9\"]= m[\"Open\"] / m[\"EMA_9\"]\n\n    m[\"Body_over_ATR\"] = (m[\"Close\"] - m[\"Open\"]) / m[\"ATR\"]\n\n    m[\"Prev_Close\"] = m[\"Close\"].shift(1)\n    m[\"Prev_Open\"]  = m[\"Open\"].shift(1)\n    m[\"Prev_High\"]  = m[\"High\"].shift(1)\n    return m\n\ndef abs_top_window(df: pd.DataFrame, d0: pd.Timestamp, lookback_days: int, exclude_days: int):\n    if df.empty: return (np.nan, np.nan)\n    cutoff = d0 - pd.Timedelta(days=exclude_days)\n    wstart = cutoff - pd.Timedelta(days=lookback_days)\n    win = df[(df.index > wstart) & (df.index <= cutoff)]\n    if win.empty: return (np.nan, np.nan)\n    return float(win[\"Low\"].min()), float(win[\"High\"].max())\n\ndef pos_between(val, lo, hi):\n    if any(pd.isna(t) for t in (val, lo, hi)) or hi <= lo: return np.nan\n    return max(0.0, min(1.0, float((val - lo) / (hi - lo))))\n\ndef _mold_on_row(rx: pd.Series) -> bool:\n    if pd.isna(rx.get(\"Prev_Close\")) or pd.isna(rx.get(\"ADV20_$\")):\n        return False\n    if rx[\"Prev_Close\"] < P[\"price_min\"] or rx[\"ADV20_$\"] < P[\"adv20_min_usd\"]:\n        return False\n    vol_avg = rx[\"VOL_AVG\"]\n    if pd.isna(vol_avg) or vol_avg <= 0: return False\n    vol_sig = max(rx[\"Volume\"]/vol_avg, rx[\"Prev_Volume\"]/vol_avg)\n    checks = [\n        (rx[\"TR\"] / rx[\"ATR\"]) >= P[\"atr_mult\"],\n        vol_sig                 >= P[\"vol_mult\"],\n        rx[\"Slope_9_5d\"]        >= P[\"slope5d_min\"],\n        rx[\"High_over_EMA9_div_ATR\"] >= P[\"high_ema9_mult\"],\n    ]\n    return all(bool(x) and np.isfinite(x) for x in checks)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Universal Scanner Engine Compatible Function â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef scan_symbol(symbol: str, start_date: str, end_date: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    ðŸŽ¯ STANDARDIZED SCAN_SYMBOL FUNCTION\n\n    Compatible with Universal Scanner Engine\n    Maintains original Backside Para B logic\n    \"\"\"\n    try:\n        # Fetch data using original function\n        df = fetch_daily(symbol, start_date, end_date)\n        if df.empty:\n            return []\n\n        # Add original metrics\n        m = add_daily_metrics(df)\n        if len(m) < 3:  # Need at least 3 rows for D-2, D-1, D0 analysis\n            return []\n\n        results = []\n\n        # Original scanning logic (adapted for single symbol)\n        for i in range(2, len(m)):\n            d0 = m.index[i]\n            r0 = m.iloc[i]       # D0\n            r1 = m.iloc[i-1]     # D-1\n            r2 = m.iloc[i-2]     # D-2\n\n            # Backside vs D-1 close\n            lo_abs, hi_abs = abs_top_window(m, d0, P[\"abs_lookback_days\"], P[\"abs_exclude_days\"])\n            pos_abs_prev = pos_between(r1[\"Close\"], lo_abs, hi_abs)\n            if not (pd.notna(pos_abs_prev) and pos_abs_prev <= P[\"pos_abs_max\"]):\n                continue\n\n            # Choose trigger\n            trigger_ok = False; trig_row = None; trig_tag = \"-\"\n            if P[\"trigger_mode\"] == \"D1_only\":\n                if _mold_on_row(r1): trigger_ok, trig_row, trig_tag = True, r1, \"D-1\"\n            else:\n                if _mold_on_row(r1): trigger_ok, trig_row, trig_tag = True, r1, \"D-1\"\n                elif _mold_on_row(r2): trigger_ok, trig_row, trig_tag = True, r2, \"D-2\"\n            if not trigger_ok:\n                continue\n\n            # D-1 must be green\n            if not (pd.notna(r1[\"Body_over_ATR\"]) and r1[\"Body_over_ATR\"] >= P[\"d1_green_atr_min\"]):\n                continue\n\n            # Absolute D-1 volume floor (shares)\n            if P[\"d1_volume_min\"] is not None:\n                if not (pd.notna(r1[\"Volume\"]) and r1[\"Volume\"] >= P[\"d1_volume_min\"]):\n                    continue\n\n            # Optional relative D-1 vol multiple\n            if P[\"d1_vol_mult_min\"] is not None:\n                if not (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"] > 0 and (r1[\"Volume\"]/r1[\"VOL_AVG\"]) >= P[\"d1_vol_mult_min\"]):\n                    continue\n\n            # D-1 > D-2 highs & close\n            if P[\"enforce_d1_above_d2\"]:\n                if not (pd.notna(r1[\"High\"]) and pd.notna(r2[\"High\"]) and r1[\"High\"] > r2[\"High\"]\n                        and pd.notna(r1[\"Close\"]) and pd.notna(r2[\"Close\"]) and r1[\"Close\"] > r2[\"Close\"]):\n                    continue\n\n            # D0 gates\n            if pd.isna(r0[\"Gap_over_ATR\"]) or r0[\"Gap_over_ATR\"] < P[\"gap_div_atr_min\"]:\n                continue\n            if P[\"require_open_gt_prev_high\"] and not (r0[\"Open\"] > r1[\"High\"]):\n                continue\n            if pd.isna(r0[\"Open_over_EMA9\"]) or r0[\"Open_over_EMA9\"] < P[\"open_over_ema9_min\"]:\n                continue\n\n            # Calculate additional metrics for result\n            d1_vol_mult = (r1[\"Volume\"]/r1[\"VOL_AVG\"]) if (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"]>0) else np.nan\n            volsig_max  = (max(r1[\"Volume\"]/r1[\"VOL_AVG\"], r2[\"Volume\"]/r2[\"VOL_AVG\"])\n                           if (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"]>0 and pd.notna(r2[\"VOL_AVG\"]) and r2[\"VOL_AVG\"]>0)\n                           else np.nan)\n\n            # âœ… STANDARDIZED RESULT FORMAT for Universal Scanner Engine\n            result = {\n                'symbol': symbol,\n                'ticker': symbol,  # Required field for Universal Scanner Engine\n                'date': d0.strftime(\"%Y-%m-%d\"),\n                'scanner_type': 'backside_para_b',\n\n                # Core metrics (standardized field names)\n                'gap_percent': round(float(r0[\"Gap_over_ATR\"]), 2),\n                'volume_ratio': round(float(d1_vol_mult), 2) if pd.notna(d1_vol_mult) else None,\n                'signal_strength': 'Strong' if r0[\"Gap_over_ATR\"] > 1.0 else 'Moderate',\n                'entry_price': round(float(r0[\"Open\"]), 2),\n                'target_price': round(float(r0[\"Open\"] * 1.05), 2),  # 5% target\n\n                # Original detailed metrics (preserved)\n                'trigger': trig_tag,\n                'pos_abs_1000d': round(float(pos_abs_prev), 3),\n                'd1_body_atr': round(float(r1[\"Body_over_ATR\"]), 2),\n                'd1_volume_shares': int(r1[\"Volume\"]) if pd.notna(r1[\"Volume\"]) else None,\n                'd1_vol_avg_ratio': round(float(d1_vol_mult), 2) if pd.notna(d1_vol_mult) else None,\n                'vol_sig_max': round(float(volsig_max), 2) if pd.notna(volsig_max) else None,\n                'gap_atr': round(float(r0[\"Gap_over_ATR\"]), 2),\n                'open_prev_high': bool(r0[\"Open\"] > r1[\"High\"]),\n                'open_ema9_ratio': round(float(r0[\"Open_over_EMA9\"]), 2),\n                'd1_above_d2_high': bool(r1[\"High\"] > r2[\"High\"]),\n                'd1_close_above_d2': bool(r1[\"Close\"] > r2[\"Close\"]),\n                'slope_9_5d': round(float(r0[\"Slope_9_5d\"]), 2) if pd.notna(r0[\"Slope_9_5d\"]) else None,\n                'high_ema9_atr_trigger': round(float(trig_row[\"High_over_EMA9_div_ATR\"]), 2),\n                'adv20_usd': round(float(r0[\"ADV20_$\"])) if pd.notna(r0[\"ADV20_$\"]) else None,\n            }\n\n            results.append(result)\n\n        return results\n\n    except Exception as e:\n        print(f\"Error scanning {symbol}: {str(e)}\")\n        return []\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Scanner Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€\nSCANNER_CONFIG = {\n    'name': 'Standardized Backside Para B Scanner',\n    'description': 'Daily-only \"A+ para, backside\" scan - lite mold with institutional standardization',\n    'timeframe': 'Daily',\n    'original_path': '/Users/michaeldurante/.anaconda/working code/backside daily para/backside para b.py',\n    'standardized': True,\n    'universal_compatible': True\n}",
  "start_date": "2024-01-01",
  "end_date": "2024-05-31",
  "use_real_scan": true
}