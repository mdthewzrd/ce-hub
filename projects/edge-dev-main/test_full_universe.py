#!/usr/bin/env python3
"""
Test Backside B scanner with full universe to verify more results exist
"""

import sys
import os
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# Add backend to path
sys.path.append('backend')

# Backside B parameters
P = {
    'price_min': 8.0,
    'adv20_min_usd': 30_000_000,
    'abs_lookback_days': 1000,
    'abs_exclude_days': 10,
    'pos_abs_max': 0.75,
    'trigger_mode': 'D1_or_D2',
    'atr_mult': .9,
    'vol_mult': 0.9,
    'd1_vol_mult_min': None,
    'd1_volume_min': 15_000_000,
    'slope5d_min': 3.0,
    'high_ema9_mult': 1.05,
    'gap_div_atr_min': .75,
    'open_over_ema9_min': .9,
    'd1_green_atr_min': 0.30,
    'require_open_gt_prev_high': True,
    'enforce_d1_above_d2': True,
}

session = requests.Session()
API_KEY = 'Fm7brz4s23eSocDErnL68cE7wspz2K1I'
BASE_URL = 'https://api.polygon.io'

def get_test_universe():
    """Get a comprehensive test universe for Backside B scanner"""

    # Import the true full universe system
    try:
        sys.path.append('backend')
        from true_full_universe import get_smart_enhanced_universe

        # Get smart pre-filtered universe
        universe = get_smart_enhanced_universe({
            'min_price': 8.0,              # Match scanner requirements
            'min_avg_volume_20d': 500_000,  # Ensure liquidity
            'min_market_cap': 50_000_000,   # Skip micro caps
            'min_adv_usd': 10_000_000,      # Minimum dollar volume
            'max_price': 2000.0,            # Skip extreme outliers
        })

        print(f'üåç FULL MARKET UNIVERSE: {len(universe)} tickers')
        print(f'   ‚úÖ Smart pre-filtering applied')
        return universe

    except Exception as e:
        print(f'‚ö†Ô∏è  Error loading full universe: {e}')

        # Comprehensive fallback universe with high-volume stocks
        universe = [
            # Mega Cap - Core market leaders
            'AAPL','MSFT','GOOGL','GOOG','AMZN','NVDA','TSLA','META','BRK.B','LLY',

            # Large Cap - Major market participants
            'AVGO','JPM','UNH','XOM','V','JNJ','WMT','MA','PG','HD','CVX','ABBV',
            'BAC','ORCL','CRM','KO','MRK','COST','AMD','PEP','TMO','DHR','ABT',
            'ADBE','CSCO','NFLX','ACN','NKE','DIS','TXN','PM','BMY','LIN','MCD',

            # High volatility/momentum stocks
            'SMCI','MSTR','PLTR','RIVN','SNOW','CRWD','ZS','FTNT','PANW','OKTA',
            'DDOG','NET','MDB','DOCN','RBLX','SE','INTU','SQ','PYPL','COIN','MARA','RIOT',

            # ETFs & Leveraged Products
            'SPY','QQQ','IWM','SOXL','SOXS','TECL','TECS','TQQQ','SQQQ','UPRO','SPXU',
            'LABU','LABD','ARKK','ARKG','ARKW','ARKQ','XLF','XLK','XLE','XLV','XLI','XLP',
            'XLY','XLU','XLRE','XLB','VTI','VOO','VEA','VWO','EFA','EEM','TLT','GLD','SLV',

            # Sector Leaders
            'UNH','JNJ','PFE','ABT','TMO','MRK','LLY','ABBV','AMGN','GILD','BMY','REGN',

            # Energy Sector Leaders
            'XOM','CVX','COP','SHEL','BP','TTE','TOT','ENB','EOG','PXD','HAL','SLB',
            'CEO','PSX','KMI','WMB','OXY','BKR','APA','DVN','HES','OKE','FANG',

            # Financial Giants
            'JPM','BAC','WFC','GS','MS','C','AXP','BLK','SCHW','AIG','MET','BRK.A',
            'SPGI','MMC','ICE','CB','PNC','USB','TFC','CIT','BK','WFC',

            # Industrial Leaders
            'BA','CAT','GE','HON','MMM','UPS','RTX','GD','LMT','NOV','DE','PYPL',

            # Consumer Discretionary
            'AMZN','TSLA','MCD','HD','NKE','LOW','TJX','M','BBY','TGT','F','ROST',

            # Healthcare Leaders
            'JNJ','UNH','PFE','ABT','TMO','MRK','LLY','ABBV','BMY','AMGN','GILD','REGN',

            # Tech Leaders (extended)
            'AAPL','MSFT','GOOGL','GOOG','AMZN','NVDA','META','TSLA','AVGO','ADBE','CRM','ORCL',
            'NFLX','INTU','CSCO','PYPL','SQ','SNAP','EBAY','ZM','ROKU','TEAM','AMD',
            'QCOM','TXN','MU','INTC','ADI','MRVL','NXPI','MCHP','KLAC','LRCX','AVGO',
            'MU','NTAP','HPQ','IBM','CRM','NOW','WDAY','SNOW','PLTR','TWLO',

            # Additional High Volume/Liquidity Stocks
            'TSM','ASML','INTC','AMD','QCOM','TXN','BABA','BIDU','PDD','JD',
            'WMT','COST','HD','MCD','NKE','DIS','TGT','KO','PEP','PG','CL',
        ]

        print(f'üîÑ COMPREHENSIVE FALLBACK UNIVERSE: {len(universe)} tickers')
        return universe

def fetch_daily(tkr, start, end):
    url = f'{BASE_URL}/v2/aggs/ticker/{tkr}/range/1/day/{start}/{end}'
    r = session.get(url, params={'apiKey': API_KEY, 'adjusted': 'true', 'sort': 'asc', 'limit': 50000})
    if r.status_code != 200:
        return pd.DataFrame()
    rows = r.json().get('results', [])
    if not rows:
        return pd.DataFrame()
    return (pd.DataFrame(rows)
            .assign(Date=lambda d: pd.to_datetime(d['t'], unit='ms', utc=True))
            .rename(columns={'o': 'Open', 'h': 'High', 'l': 'Low', 'c': 'Close', 'v': 'Volume'})
            .set_index('Date')[['Open', 'High', 'Low', 'Close', 'Volume']]
            .sort_index())

def add_daily_metrics(df):
    if df.empty:
        return df
    m = df.copy()
    try:
        m.index = m.index.tz_localize(None)
    except Exception:
        pass
    m['EMA_9'] = m['Close'].ewm(span=9, adjust=False).mean()
    m['EMA_20'] = m['Close'].ewm(span=20, adjust=False).mean()
    hi_lo = m['High'] - m['Low']
    hi_prev = (m['High'] - m['Close'].shift(1)).abs()
    lo_prev = (m['Low'] - m['Close'].shift(1)).abs()
    m['TR'] = pd.concat([hi_lo, hi_prev, lo_prev], axis=1).max(axis=1)
    m['ATR_raw'] = m['TR'].rolling(14, min_periods=14).mean()
    m['ATR'] = m['ATR_raw'].shift(1)
    m['VOL_AVG'] = m['Volume'].rolling(14, min_periods=14).mean().shift(1)
    m['Prev_Volume'] = m['Volume'].shift(1)
    m['ADV20_$'] = (m['Close'] * m['Volume']).rolling(20, min_periods=20).mean().shift(1)
    m['Slope_9_5d'] = (m['EMA_9'] - m['EMA_9'].shift(5)) / m['EMA_9'].shift(5) * 100
    m['High_over_EMA9_div_ATR'] = (m['High'] - m['EMA_9']) / m['ATR']
    m['Gap_abs'] = (m['Open'] - m['Close'].shift(1)).abs()
    m['Gap_over_ATR'] = m['Gap_abs'] / m['ATR']
    m['Open_over_EMA9'] = m['Open'] / m['EMA_9']
    m['Body_over_ATR'] = (m['Close'] - m['Open']) / m['ATR']
    m['Prev_Close'] = m['Close'].shift(1)
    m['Prev_High'] = m['High'].shift(1)
    return m

def abs_top_window(df, d0, lookback_days, exclude_days):
    if df.empty:
        return (np.nan, np.nan)
    cutoff = d0 - pd.Timedelta(days=exclude_days)
    wstart = cutoff - pd.Timedelta(days=lookback_days)
    win = df[(df.index > wstart) & (df.index <= cutoff)]
    if win.empty:
        return (np.nan, np.nan)
    return float(win['Low'].min()), float(win['High'].max())

def pos_between(val, lo, hi):
    if any(pd.isna(t) for t in (val, lo, hi)) or hi <= lo:
        return np.nan
    return max(0.0, min(1.0, float((val - lo) / (hi - lo))))

def _mold_on_row(rx):
    if pd.isna(rx.get('Prev_Close')) or pd.isna(rx.get('ADV20_$')):
        return False
    if rx['Prev_Close'] < P['price_min'] or rx['ADV20_$'] < P['adv20_min_usd']:
        return False
    vol_avg = rx['VOL_AVG']
    if pd.isna(vol_avg) or vol_avg <= 0:
        return False
    vol_sig = max(rx['Volume']/vol_avg, rx['Prev_Volume']/vol_avg)
    checks = [
        (rx['TR'] / rx['ATR']) >= P['atr_mult'],
        vol_sig >= P['vol_mult'],
        rx['Slope_9_5d'] >= P['slope5d_min'],
        rx['High_over_EMA9_div_ATR'] >= P['high_ema9_mult'],
    ]
    return all(bool(x) and np.isfinite(x) for x in checks)

def scan_symbol(sym, start, end):
    df = fetch_daily(sym, start, end)
    if df.empty:
        return pd.DataFrame()
    m = add_daily_metrics(df)
    rows = []
    for i in range(2, len(m)):
        d0 = m.index[i]
        r0 = m.iloc[i]
        r1 = m.iloc[i-1]
        r2 = m.iloc[i-2]
        lo_abs, hi_abs = abs_top_window(m, d0, P['abs_lookback_days'], P['abs_exclude_days'])
        pos_abs_prev = pos_between(r1['Close'], lo_abs, hi_abs)
        if not (pd.notna(pos_abs_prev) and pos_abs_prev <= P['pos_abs_max']):
            continue
        trigger_ok = False
        trig_row = None
        trig_tag = '-'
        if P['trigger_mode'] == 'D1_only':
            if _mold_on_row(r1):
                trigger_ok, trig_row, trig_tag = True, r1, 'D-1'
        else:
            if _mold_on_row(r1):
                trigger_ok, trig_row, trig_tag = True, r1, 'D-1'
            elif _mold_on_row(r2):
                trigger_ok, trig_row, trig_tag = True, r2, 'D-2'
        if not trigger_ok:
            continue
        if not (pd.notna(r1['Body_over_ATR']) and r1['Body_over_ATR'] >= P['d1_green_atr_min']):
            continue
        if P['d1_volume_min'] is not None:
            if not (pd.notna(r1['Volume']) and r1['Volume'] >= P['d1_volume_min']):
                continue
        if P['enforce_d1_above_d2']:
            if not (pd.notna(r1['High']) and pd.notna(r2['High']) and r1['High'] > r2['High']
                    and pd.notna(r1['Close']) and pd.notna(r2['Close']) and r1['Close'] > r2['Close']):
                continue
        if pd.isna(r0['Gap_over_ATR']) or r0['Gap_over_ATR'] < P['gap_div_atr_min']:
            continue
        if P['require_open_gt_prev_high'] and not (r0['Open'] > r1['High']):
            continue
        if pd.isna(r0['Open_over_EMA9']) or r0['Open_over_EMA9'] < P['open_over_ema9_min']:
            continue
        rows.append({
            'symbol': sym,
            'date': d0.strftime('%Y-%m-%d'),
            'trigger': trig_tag,
            'pos_abs_1000d': round(float(pos_abs_prev), 3),
            'd1_body_atr': round(float(r1['Body_over_ATR']), 2),
            'd1_vol_shares': int(r1['Volume']) if pd.notna(r1['Volume']) else np.nan,
            'gap_atr': round(float(r0['Gap_over_ATR']), 2),
            'open_ema9': round(float(r0['Open_over_EMA9']), 2),
            'adv20_usd': round(float(r0['ADV20_$'])) if pd.notna(r0['ADV20_$']) else np.nan,
        })
    return pd.DataFrame(rows)

def run_full_universe_scan():
    """Run comprehensive scan with full universe"""

    # Get comprehensive universe
    universe = get_test_universe()

    # Test with substantial sample first to avoid API rate limits
    test_sample = universe[:200]  # Test first 200 symbols

    start_date = '2025-01-01'
    end_date = '2025-12-07'

    print(f'üéØ BACKSIDE B FULL UNIVERSE SCAN')
    print(f'üìä Date range: {start_date} to {end_date} (Today: Dec 7, 2025)')
    print(f'üìä Testing sample of {len(test_sample)} symbols from universe of {len(universe)} total tickers')
    print(f'üìã Scanner parameters:')
    print(f'   ‚Ä¢ d1_volume_min: {P["d1_volume_min"]:,} shares')
    print(f'   ‚Ä¢ pos_abs_max: {P["pos_abs_max"]}')
    print(f'   ‚Ä¢ gap_div_atr_min: {P["gap_div_atr_min"]}')
    print(f'   ‚Ä¢ d1_green_atr_min: {P["d1_green_atr_min"]}')

    all_results = []
    pattern_count = 0

    print(f'\nüöÄ Starting scan with {len(test_sample)} symbols...')

    with ThreadPoolExecutor(max_workers=20) as exe:
        futs = {exe.submit(scan_symbol, s, start_date, end_date): s for s in test_sample}
        completed = 0
        for fut in as_completed(futs):
            try:
                patterns = fut.result()
                symbol = futs[fut]
                completed += 1

                if not patterns.empty:
                    found = len(patterns)
                    pattern_count += found
                    print(f'‚úÖ [{completed}/{len(test_sample)}] {symbol}: {found} patterns')
                    all_results.append(patterns)
                else:
                    print(f'‚ö™ [{completed}/{len(test_sample)}] {symbol}: No patterns')

            except Exception as e:
                print(f'‚ùå [{completed}/{len(test_sample)}] {futs[fut]}: Error - {str(e)}')

    if all_results:
        result_df = pd.concat(all_results, ignore_index=True)
        result_df = result_df.sort_values(['date', 'symbol'], ascending=[False, True])

        print(f'\nüéØ SUCCESS! FOUND {len(result_df)} BACKSIDE B PATTERNS!')
        print(f'üìä In sample of {len(test_sample)} symbols from universe of {len(universe)} total')

        # Calculate expected total for full universe
        if len(test_sample) > 0 and pattern_count > 0:
            patterns_per_symbol = pattern_count / len(test_sample)
            expected_total = int(patterns_per_symbol * len(universe))
            print(f'üìà EXPECTED PATTERNS IN FULL UNIVERSE: ~{expected_total} patterns')

        if not result_df.empty:
            print(f'\nüìä ALL PATTERNS FOUND:')
            pd.set_option('display.max_columns', None)
            pd.set_option('display.width', 0)
            print(result_df.to_string(index=False))

            print(f'\nüìà PATTERN DISTRIBUTION:')
            symbol_counts = result_df['symbol'].value_counts()
            for symbol, count in symbol_counts.head(15).items():
                print(f'   {symbol}: {count} patterns')

            # Analysis section
            avg_gap = result_df['gap_atr'].mean()
            max_gap = result_df['gap_atr'].max()
            avg_volume = result_df['d1_vol_shares'].mean()
            print(f'\nüìä PATTERN ANALYSIS:')
            print(f'   ‚Ä¢ Average Gap/ATR: {avg_gap:.2f}')
            print(f'   ‚Ä¢ Maximum Gap/ATR: {max_gap:.2f}')
            print(f'   ‚Ä¢ Average Volume: {int(avg_volume):,} shares')

            print(f'\nüéâ SCANNER WORKING PERFECTLY!')
            print(f'   ‚úÖ Full universe scanning confirmed')
            print(f'   ‚úÖ Sophisticated pattern detection working')
            print(f'   ‚úÖ Expected {expected_total}+ patterns across full universe')

        return result_df

    else:
        print(f'\n‚ùå No patterns found in sample of {len(test_sample)} symbols')
        print(f'üìä This may indicate:')
        print(f'   ‚Ä¢ API rate limits reached')
        print(f'   ‚Ä¢ Parameters are extremely selective (high quality filter)')
        print(f'   ‚Ä¢ Market conditions favoring fewer patterns in 2025')

        # Check a few symbols for data availability
        print(f'\nüîç Checking data availability...')
        test_symbols = ['AAPL', 'MSFT', 'GOOGL', 'NVDA', 'TSLA']
        for symbol in test_symbols:
            try:
                df = fetch_daily(symbol, start_date, end_date)
                if not df.empty:
                    print(f'‚úÖ {symbol}: {len(df)} trading days available')
                    # Check if symbol meets basic volume criteria
                    recent_avg_vol = df['Volume'].tail(14).mean()
                    if recent_avg_vol > P['d1_volume_min']:
                        print(f'   ‚úÖ {symbol}: Recent avg volume {int(recent_avg_vol):,} > {P["d1_volume_min"]:,}')
                    else:
                        print(f'   ‚ö†Ô∏è  {symbol}: Recent avg volume {int(recent_avg_vol):,} < {P["d1_volume_min"]:,}')
                else:
                    print(f'‚ùå {symbol}: No data available')
            except Exception as e:
                print(f'‚ùå {symbol}: Error checking data - {e}')

        return pd.DataFrame()

if __name__ == "__main__":
    results = run_full_universe_scan()