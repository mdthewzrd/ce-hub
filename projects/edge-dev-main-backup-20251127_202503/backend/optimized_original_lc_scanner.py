import pandas as pd
import requests
import time
import numpy as np
import pandas_market_calendars as mcal
import aiohttp
import asyncio
import pandas as pd
from multiprocessing import Pool, cpu_count
from concurrent.futures import ProcessPoolExecutor
from tabulate import tabulate
import webbrowser
import plotly.graph_objects as go
import sys
from concurrent.futures import ThreadPoolExecutor
import dask
from dask.distributed import Client, as_completed
import dask.dataframe as dd
import datetime
import logging
import backoff

nyse = mcal.get_calendar('NYSE')
executor = ThreadPoolExecutor()

import warnings
warnings.filterwarnings("ignore")

if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

DATE = "2025-01-01"

# Replace with your Polygon API Key
API_KEY = '4r6MZNWLy2ucmhVI7fY8MrvXfXTSmxpy'
BASE_URL = "https://api.polygon.io"

# MAX WORKERS FOR CONCURRENCY - REDUCED FOR PERFORMANCE OPTIMIZATION
# Original: 12, Reduced to 6 to prevent API quota exhaustion and resource contention
MAX_WORKERS = 6

# Global variables for external access
df_lc = None
df_sc = None
START_DATE = None
END_DATE = None
START_DATE_DT = None
END_DATE_DT = None
start_date_70_days_before = None
DATES = None

def adjust_daily(df):
    # df = pd.DataFrame(data)
    df['date'] = pd.to_datetime(df['t'], unit='ms')
    df['date'] = df['date'].dt.date
    df['pdc'] = df['c'].shift(1)
    df['high_low'] = df['h'] - df['l']  # High - Low
    df['high_pdc'] = abs(df['h'] - df['pdc'])  # High - Previous Day Close
    df['low_pdc'] = abs(df['l'] - df['pdc'])  # Low - Previous Day Close
    # True Range (TR) is the max of high-low, high-pdc, low-pdc
    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)
    # Calculate the ATR (using a 14-day rolling window)
    df['atr'] = df['true_range'].rolling(window=14).mean()
    # Drop intermediate columns for clean output
    df.drop(['high_low', 'high_pdc', 'low_pdc'], axis=1, inplace=True)


    df['h1'] = df['h'].shift(1)
    df['h2'] = df['h'].shift(2)
    df['h3'] = df['h'].shift(3)

    df['c1'] = df['c'].shift(1)
    df['c2'] = df['c'].shift(2)
    df['c3'] = df['c'].shift(3)

    df['o1'] = df['o'].shift(1)
    df['o2'] = df['o'].shift(2)

    df['l1'] = df['l'].shift(1)
    df['l2'] = df['l'].shift(2)

    df['v_ua1'] = df['v_ua'].shift(1)
    df['v1'] = df['v'].shift(1)
    df['v2'] = df['v'].shift(2)

    df['dol_v'] = (df['c'] * df['v'])
    df['dol_v1'] = df['dol_v'].shift(1)
    df['dol_v2'] = df['dol_v'].shift(2)


    df['close_range'] = (df['c'] - df['l'])/(df['h'] - df['l'])
    df['close_range1'] = df['close_range'].shift(1)
    df['close_range2'] = df['close_range'].shift(2)

    df['gap_atr'] = ((df['o'] - df['pdc'])/df['atr'])
    df['gap_atr1'] = ((df['o1'] - df['c2'])/df['atr'])

    df['gap_pdh_atr'] = ((df['o'] - df['h1'])/df['atr'])

    df['high_chg'] = (df['h'] - df['o'])
    df['high_chg_atr'] = ((df['h'] - df['o'])/df['atr'])
    # df['high_chg_atr'] = round(df['high_chg_atr'], 2)
    df['high_chg_atr1'] = ((df['h1'] - df['o1'])/df['atr'])
    df['high_chg_atr2'] = ((df['h2'] - df['o2'])/df['atr'])

    df['high_chg_from_pdc_atr'] = ((df['h'] - df['c1'])/df['atr'])
    df['high_chg_from_pdc_atr1'] = ((df['h1'] - df['c2'])/df['atr'])

    df['pct_change'] = round(((df['c'] / df['c1']) - 1)*100, 2)

    df['ema9'] = df['c'].ewm(span=9, adjust=False).mean().fillna(0)
    df['ema20'] = df['c'].ewm(span=20, adjust=False).mean().fillna(0)
    df['ema50'] = df['c'].ewm(span=50, adjust=False).mean().fillna(0)
    df['ema200'] = df['c'].ewm(span=200, adjust=False).mean().fillna(0)

    df['ema20_2'] = df['ema20'].shift(2)


    df['ema9_1'] = df['ema9'].shift(1)
    df['ema20_1'] = df['ema20'].shift(1)
    df['ema50_1'] = df['ema50'].shift(1)

    df['dist_h_9ema'] = (df['h'] - df['ema9'])
    df['dist_h_20ema'] = (df['h'] - df['ema20'])
    df['dist_h_50ema'] = (df['h'] - df['ema50'])
    df['dist_h_200ema'] = (df['h'] - df['ema200'])

    df['dist_h_9ema1'] = df['dist_h_9ema'].shift(1)
    df['dist_h_20ema1'] = df['dist_h_20ema'].shift(1)
    df['dist_h_50ema1'] = df['dist_h_50ema'].shift(1)
    df['dist_h_200ema1'] = df['dist_h_200ema'].shift(1)

    df['dist_h_9ema_atr'] = df['dist_h_9ema'] /df['atr']
    df['dist_h_20ema_atr'] = df['dist_h_20ema'] /df['atr']
    df['dist_h_50ema_atr'] = df['dist_h_50ema'] /df['atr']
    df['dist_h_200ema_atr'] = df['dist_h_200ema'] /df['atr']

    df['dist_h_9ema_atr1'] = df['dist_h_9ema1'] /df['atr']
    df['dist_h_20ema_atr1'] = df['dist_h_20ema1'] /df['atr']
    df['dist_h_50ema_atr1'] = df['dist_h_50ema1'] /df['atr']
    df['dist_h_200ema_atr1'] = df['dist_h_200ema1'] /df['atr']

    df['dist_h_9ema2'] = df['dist_h_9ema'].shift(2)
    df['dist_h_9ema3'] = df['dist_h_9ema'].shift(3)
    df['dist_h_9ema4'] = df['dist_h_9ema'].shift(4)

    df['dist_h_20ema2'] = df['dist_h_20ema'].shift(2)
    df['dist_h_20ema3'] = df['dist_h_20ema'].shift(3)
    df['dist_h_20ema4'] = df['dist_h_20ema'].shift(4)
    df['dist_h_20ema5'] = df['dist_h_20ema'].shift(5)

    df['dist_h_9ema_atr2'] = df['dist_h_9ema2'] /df['atr']
    df['dist_h_9ema_atr3'] = df['dist_h_9ema3'] /df['atr']
    df['dist_h_9ema_atr4'] = df['dist_h_9ema4'] /df['atr']

    df['dist_h_20ema_atr2'] = df['dist_h_20ema2'] /df['atr']
    df['dist_h_20ema_atr3'] = df['dist_h_20ema3'] /df['atr']
    df['dist_h_20ema_atr4'] = df['dist_h_20ema4'] /df['atr']

    df['lowest_low_20'] = df['l'].rolling(window=20, min_periods=1).min()
    df['lowest_low_20_2'] = df['lowest_low_20'].shift(2)
    df['h_dist_to_lowest_low_20_atr'] = ((df['h'] - df['lowest_low_20'])/df['atr'])

    df['lowest_low_30'] = df['l'].rolling(window=30, min_periods=1).min()
    df['lowest_low_30_1'] = df['lowest_low_30'].shift(1)

    df['h_dist_to_lowest_low_30'] = (df['h'] - df['lowest_low_30'])

    df['lowest_low_5'] = df['l'].rolling(window=5, min_periods=1).min()
    df['h_dist_to_lowest_low_5_atr'] = ((df['h'] - df['lowest_low_5'])/df['atr'])

    df['highest_high_100'] = df['h'].rolling(window=100).max()
    df['highest_high_100_1'] = df['highest_high_100'].shift(1)

    df['highest_high_250'] = df['h'].rolling(window=250, min_periods=1).max()
    df['highest_high_250_1'] = df['highest_high_250'].shift(1)

    df['highest_high_5'] = df['h'].rolling(window=5, min_periods=1).max()

    df['highest_high_50'] = df['h'].rolling(window=50, min_periods=1).max()
    df['highest_high_50_1'] = df['highest_high_50'].shift(1)
    df['highest_high_50_4'] = df['highest_high_50'].shift(4)

    df['highest_high_20'] = df['h'].rolling(window=20, min_periods=1).max()
    df['highest_high_20_2'] = df['highest_high_20'].shift(2)

    df['highest_high_100'] = df['h'].rolling(window=100, min_periods=1).max()
    df['highest_high_100_4'] = df['highest_high_100'].shift(4)

    return df

def adjust_intraday(df):
    #df=pd.DataFrame(results)
    df['date_time']=pd.to_datetime(df['t']*1000000).dt.tz_localize('UTC')
    df['date_time']=df['date_time'].dt.tz_convert('US/Eastern')

    #df['Date Time'] = pd.to_datetime(df['Date Time'])

    # format the datetime objects to "yyyy-mm-dd hh:mm:ss" format
    df['date_time'] = df['date_time'].dt.strftime('%Y-%m-%d %H:%M:%S')
    df['date_time'] = pd.to_datetime(df['date_time'])

    # df=df.set_index(['date_time']).asfreq('1min')
    # df.v = df.v.fillna(0)
    # df[['c']] = df[['c']].ffill()
    # df['h'].fillna(df['c'], inplace=True)
    # df['l'].fillna(df['c'], inplace=True)
    # df['o'].fillna(df['c'], inplace=True)
    # df=df.between_time('04:00', '20:00')
    # df = df.reset_index(level=0)

    df['time'] = pd.to_datetime(df['date_time']).dt.time
    df['date'] = pd.to_datetime(df['date_time']).dt.date

    # daily_v_sum = df.groupby(df['date_time'].dt.date)['v'].sum()
    # valid_dates = daily_v_sum[daily_v_sum > 0].index
    # df = df[df['date_time'].dt.date.isin(valid_dates)]
    # # df = df.reset_index(level=0)
    # df = df.reset_index(drop=True)



    df['time_int'] = df['date_time'].dt.hour * 100 + df['date_time'].dt.minute
    df['date_int'] = df['date_time'].dt.strftime('%Y%m%d').astype(int)



    df['date_time_int'] = df['date_int'].astype(str) + '.' + df['time_int'].astype(str)
    df['date_time_int'] = df['date_time_int'].astype(float)


    df['v_sum'] = df.groupby('date')['v'].cumsum()

    df['hod_all'] = df.groupby(df['date'])['h'].cummax().fillna(0)



    return df

def check_high_lvl_filter_lc(df):

    '''
    # df = df1.iloc[-1]
    # df = df1.tail(1)

    ### SCORE
    # 1. Atr exp: 20
    # 2. EMA Dist: 30
    # 3. Multi-day Burst: 20
    # 4. Vol exp: 10
    # 5. Gaps between: 20

    # Total Score: 100

    # ======================================================================
    # 1) ATR Expansion score (weight target ~20 pts)
    #    Prefer your normalized multiple if you have it: high_chg_atr1 (≈ (high-low)/ATR or similar).
    # ======================================================================
    atr_mult = df.get('high_chg_atr1', 0.0)

    df['score_atr'] = np.select(
        [
            atr_mult >= 3,
            (atr_mult >= 2) & (atr_mult < 3),
            (atr_mult >= 1) & (atr_mult < 2),
            (atr_mult >= 0.5) & (atr_mult < 1),
        ],
        [20, 18, 15, 12],
        default=0
    )


    # ======================================================================
    # 2) EMA Distance score (weight target ~30 pts)
    #    Use your ATR-normalized deviations; prefer 20EMA if available, else 9EMA.
    # ======================================================================
    ema_dev = np.where(df.get('dist_h_9ema_atr1', np.nan).astype(float) > 0,
                    df['dist_h_9ema_atr1'],
                    df.get('dist_9ema_atr1', 0.0))

    df['score_ema'] = np.select(
        [
            ema_dev >= 4.0,
            (ema_dev >= 3.0) & (ema_dev < 4.0),
            (ema_dev >= 2.0) & (ema_dev < 3.0),
            (ema_dev >= 1.0) & (ema_dev < 2.0),
        ],
        [30, 25, 20, 15],
        default=0
    )



    # ======================================================================
    # 3) Multi-Day Burst score (weight target ~25 pts)
    #    Quantifies: consecutive up days + range expansion + at least one gap
    #    - up_streak: consecutive closes > prev close
    #    - range_exp_count: how many recent days expanded range vs prior
    #    - has_gap: gap ≥ 3% today (you can extend to prior days if you track gap_pct_1, gap_pct_2, ...)
    # ======================================================================
    # up_streak (vectorized 3-day check using your lagged closes if present)
    has_c2 = 'c2' in df.columns
    has_c3 = 'c3' in df.columns

    up1 = ((df['c1'] > df['c2'])&(df['c1'] > df['o1'])&(df['h1'] > df['h2'])).astype(int) if has_c2 else 0
    up2 = ((df['c2'] > df['c3'])&(df['c2'] > df['o2'])&(df['h2'] > df['h3'])).astype(int) if (has_c2 and has_c3) else 0
    # crude consecutive count over last 3 bars (today vs yesterday, yesterday vs day before)
    up_streak3 = up1 + up2  # yields 0,1,2 (treat 2 as 3+ for scoring tiers below)

    # range expansion: compare today vs yesterday; if you also have range2 vs range3, add it
    has_range2 = 'range2' in df.columns
    rng_today = df.get('range1', 0.0)
    rng_yday  = df.get('range2', 0.0) if has_range2 else 0.0
    rng_yday_atr = df.get('high_chg_atr2', 0.0)
    range_exp1 = ((rng_today > rng_yday) & (rng_yday_atr>=0.5)).astype(int)
    range_exp_count = range_exp1  # extend with more lags if you maintain them

    # gap today
    has_gap = (df.get('gap_atr1', 0.0) >= 0.3).astype(int)

    # assemble a tiered burst score
    df['score_burst'] = np.select(
        [
            (up_streak3 >= 2) & (range_exp_count >= 1) & (has_gap == 1),   # ~3+ up days feel (2 comparisons true), 1+ range expansion, gap
            (up_streak3 >= 2) & (range_exp_count >= 1),
            (up_streak3 >= 2),
            (up_streak3 == 1) & (range_exp_count >= 1) & (has_gap == 1),
            (up_streak3 == 1),
        ],
        [20, 17.5, 15, 12.5, 10],
        default=10  # minimal burst evidence
    )



    # ======================================================================
    # 4) Volume / RVOL score (weight target ~15 pts)
    #    If you have rvol1 use it; else proxy with dollar volume tiers.
    # ======================================================================
    rvol = df.get('rvol1', np.nan).astype(float)
    has_rvol = np.isfinite(rvol)

    df['score_vol'] = np.select(
        [
            rvol >= 2,
            (rvol >= 1.5) & (rvol < 2),
            (rvol >= 1) & (rvol < 1.5),
            (rvol >= 0.5) & (rvol < 1),
        ],
        [10, 8, 5, 2],
        default=0
    )


    # ======================================================================
    # 5) Gap Behavior score (weight target ~10 pts)
    #    Uses your existing gap_pct (today vs yesterday).
    #    If you maintain prior gap columns (gap_pct_1, gap_pct_2) you can add a consecutive gap bonus.
    # ======================================================================
    gap = df.get('gap_atr1', 0.0)

    df['score_gap'] = np.select(
        [
            gap >= 0.5,
            (gap >= 0.3) & (gap < 0.5),
            (gap >= 0.1) & (gap < 0.3),
        ],
        [15, 10, 5],
        default=0
    )

    # Optional: consecutive gap bonus if you track gap_pct_1 / gap_pct_2, etc.
    if 'gap_atr2' in df.columns:
        consec_gaps = ((df['gap_atr1'] >= 0.3) & (df['gap_atr2'] >= 0.3)).astype(int)
        df['score_gap'] = df['score_gap'] + consec_gaps * 5  # max bonus +5



    df['parabolic_score_raw'] = (
        df['score_atr'] + df['score_ema'] + df['score_burst'] +
        df['score_vol'] + df['score_gap']
    )

    df['parabolic_score'] = df['parabolic_score_raw'].clip(upper=100)


    # Optional tiers for quick filtering
    df['parabolic_tier'] = np.select(
        [
            df['parabolic_score'] >= 90,
            (df['parabolic_score'] >= 75) & (df['parabolic_score'] < 90),
            (df['parabolic_score'] >= 60) & (df['parabolic_score'] < 75),
            (df['parabolic_score'] >= 40) & (df['parabolic_score'] < 60),
        ],
        ['A+','A','B','C'],
        default='D'
    )

    # Example hard filters to keep only prime watchlist names (tune as desired)
    df['parabolic_watch'] = (
        (df['c_ua'] >= 10) &
        (df['gap_atr'] >= 0.3) &
        (df['parabolic_score'] >= 60) &      # strong close near highs
        (df['close_range1'] >= 0.25) &
        (df['c1'] > df['o1']) &
        (df['v_ua1'] >= 10000000)  &
        (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |
        ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |
        ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |
        ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |
        ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &
        (df['ema9_1'] >= df['ema20_1'])  &
        (df['ema20_1'] >= df['ema50_1'])  &
        (df['dol_v1'] >= 500000000)         # liquidity guardrail
    ).astype(int)

    #'''


    '''
    df['lc_d2'] = (
                    (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |
                     ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |
                     ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &
                    (df['v_ua1'] >= 10000000) &
                    (df['dol_v1'] >= 500000000) &
                    (df['close_range1'] >= .6) &
                    (df['c1'] > df['o1']) &
                    (df['h1'] > df['h2']) &
                    (df['high_chg_atr1'] >= 2)).astype(int)
    df['lc_d2_1'] = (
                    (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |
                     ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |
                     ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &
                    (df['v_ua1'] >= 10000000) &
                    (df['dol_v1'] >= 500000000) &
                    (df['close_range1'] >= .6) &
                    (df['c1'] > df['o1']) &
                    (df['h1'] > df['h2']) &
                    (df['dist_h_9ema_atr1'] >= 2) &
                    (df['high_chg_atr1'] >= 1.5)).astype(int)


    df['lc_d3'] = (
                    (((df['high_pct_chg1'] >= .3) & (df['high_pct_chg2'] >= .3) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |
                     ((df['high_pct_chg1'] >= .15) & (df['high_pct_chg2'] >= .15) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |
                     ((df['high_pct_chg1'] >= .1) & (df['high_pct_chg2'] >= .1) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .06) & (df['high_pct_chg2'] >= .06) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |
                     ((df['high_pct_chg1'] >= .03) & (df['high_pct_chg2'] >= .03) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &
                    (df['v_ua1'] >= 10000000) &
                    (df['dol_v1'] >= 500000000) &
                    (df['v_ua2'] >= 10000000) &
                    (df['dol_v2'] >= 500000000) &
                    (df['close_range1'] >= .2) &
                    (df['close_range2'] >= .5) &
                    (df['c1'] > df['o1']) &
                    (df['c2'] > df['o2']) &
                    (df['h1'] > df['h2']) &
                    (df['h2'] > df['h3']) &
                    (df['high_chg_atr1'] >= 0.5) &
                    (df['high_chg_atr2'] >= 0.5)).astype(int)


    #'''



    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['l'] >= df['l1']) &
                        (df['l1'] >= df['l2']) &

                        (((df['high_pct_chg1'] >= .3) & (df['high_pct_chg'] >= .3) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['h_dist_to_lowest_low_20_pct']>=2.5)) |# & (df['gap_pct'] >=  .15)) |
                        ((df['high_pct_chg1'] >= .2) & (df['high_pct_chg'] >= .2) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['h_dist_to_lowest_low_20_pct']>=2)) |# & (df['gap_pct'] >=  .1)) |
                        ((df['high_pct_chg1'] >= .1) & (df['high_pct_chg'] >= .1) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['h_dist_to_lowest_low_20_pct']>=1.5)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg1'] >= .07) & (df['high_pct_chg'] >= .07) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['h_dist_to_lowest_low_20_pct']>=1)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg1'] >= .05) & (df['high_pct_chg'] >= .05) & (df['c_ua'] >= 90) & (df['h_dist_to_lowest_low_20_pct']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &


                        (df['high_chg_atr1'] >= 0.7) &
                        # (df['gap_atr1'] >= 0.2) &
                        # (df['close_range1'] >= 0.6) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 2) &

                        (df['high_chg_atr'] >= 1) &
                        (df['c'] >= df['o']) &
                        # (df['gap_atr'] >= 0.2) &
                        # (df['close_range'] >= 0.6) &
                        (df['dist_h_9ema_atr'] >= 1.5) &
                        (df['dist_h_20ema_atr'] >= 2) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['v_ua1'] >= 10000000) &
                        (df['dol_v1'] >= 100000000) &
                        (df['c_ua'] >= 5) &


                        ((df['high_chg_atr'] >= 1) | (df['high_chg_atr1'] >= 1))&

                        (df['h_dist_to_highest_high_20_2_atr']>=2.5)&

                        ((df['h'] >= df['highest_high_20']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']))

                        ).astype(int)

    df['lc_frontside_d2_extended'] = ((df['h'] >= df['h1']) &

                        (df['l'] >= df['l1']) &


                        (((df['high_pct_chg'] >= .5) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2.5)) |# & (df['gap_pct'] >=  .15)) |
                        ((df['high_pct_chg'] >= .3) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2)) |# & (df['gap_pct'] >=  .1)) |
                        ((df['high_pct_chg'] >= .2) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1.5)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg'] >= .15) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg'] >= .1) & (df['c_ua'] >= 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &




                        (df['high_chg_atr'] >= 1.5) &
                        (df['c'] >= df['o']) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_20ema_atr'] >= 3) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 5) &

                        (df['dist_l_9ema_atr'] >= 1) &

                        (df['h_dist_to_highest_high_20_1_atr']>=1)&

                        (df['dol_v_cum5_1']>=500000000)&


                        ((df['h'] >= df['highest_high_20']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']))

                        ).astype(int)


    df['lc_frontside_d2_extended_1'] = ((df['h'] >= df['h1']) &

                        (df['l'] >= df['l1']) &


                        (((df['high_pct_chg'] >= 1) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2.5)) |# & (df['gap_pct'] >=  .15)) |
                        ((df['high_pct_chg'] >= .5) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2)) |# & (df['gap_pct'] >=  .1)) |
                        ((df['high_pct_chg'] >= .3) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1.5)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg'] >= .2) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1)) |# & (df['gap_pct'] >=  .05)) |
                        ((df['high_pct_chg'] >= .15) & (df['c_ua'] >= 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &




                        (df['high_chg_atr'] >= 1.5) &
                        (df['c'] >= df['o']) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_20ema_atr'] >= 3) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 5) &

                        # (df['dist_l_9ema_atr'] >= 1) &

                        (df['h_dist_to_highest_high_20_1_atr']>=1)&

                        (df['dol_v_cum5_1']>=500000000)&


                        ((df['h'] >= df['highest_high_20']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']))

                        ).astype(int)

    '''

    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['pct_cng'] >= 0.5) &

                        (df['high_chg_atr1'] >= 0.5) &
                        (df['gap_atr1'] >= 0.2) &
                        (df['close_range1'] >= 0.6) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.7) &
                        (df['gap_atr'] >= 0.2) &
                        (df['close_range'] >= 0.6) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_50ema_atr'] >= 4) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['h'] >= df['highest_high_250']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']) &
                        (df['ema50'] >= df['ema200']))

                        ).astype(int)


    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['high_chg_atr1'] >= 0.5) &
                        (df['gap_atr1'] >= 0.2) &
                        (df['close_range1'] >= 0.6) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.7) &
                        (df['gap_atr'] >= 0.2) &
                        (df['close_range'] >= 0.6) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_50ema_atr'] >= 4) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['h'] >= df['highest_high_250']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']) &
                        (df['ema50'] >= df['ema200']))

                        ).astype(int)
    df['lc_backside_d3_extended_1'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['high_chg_atr1'] >= 0.5) &
                        (df['gap_atr1'] >= 0.2) &
                        (df['close_range1'] >= 0.6) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.7) &
                        (df['gap_atr'] >= 0.2) &
                        (df['close_range'] >= 0.6) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_50ema_atr'] >= 4) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['ema9'] < df['ema20']) |
                        (df['ema20'] < df['ema50']) |
                        (df['ema50'] < df['ema200']) |
                        (df['h'] < df['highest_high_250']))

                        ).astype(int)

    df['lc_frontside_d3_extended_2'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['high_chg_atr1'] >= 0.3) &
                        (df['close_range1'] >= 0.5) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1) &
                        (df['high_chg1'] >= df['high_chg']*0.4) &

                        (df['high_chg_atr'] >= 0.6) &
                        (df['gap_atr'] >= 0.2) &
                        (df['close_range'] >= 0.4) &
                        (df['dist_h_9ema_atr'] >= 1.5) &
                        (df['dist_h_20ema_atr'] >= 3) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['h'] >= df['highest_high_250']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']) &
                        (df['ema50'] >= df['ema200']))

                        ).astype(int)
    df['lc_backside_d3_extended_2'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['high_chg_atr1'] >= 0.3) &
                        (df['close_range1'] >= 0.5) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1) &
                        (df['high_chg1'] >= df['high_chg']*0.4) &

                        (df['high_chg_atr'] >= 0.6) &
                        (df['gap_atr'] >= 0.2) &
                        (df['close_range'] >= 0.4) &
                        (df['dist_h_9ema_atr'] >= 1.5) &
                        (df['dist_h_20ema_atr'] >= 3) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['ema9'] < df['ema20']) |
                        (df['ema20'] < df['ema50']) |
                        (df['ema50'] < df['ema200']) |
                        (df['h'] < df['highest_high_250']))

                        ).astype(int)

    df['lc_frontside_d4_para'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['dist_h_9ema_atr2'] >= 1) &
                        (df['dist_h_9ema_atr3'] >= 1) &
                        (df['dist_h_9ema_atr4'] >= 1) &

                        (df['c2'] >= df['o2']) &
                        (df['dist_h_20ema_atr2'] >= 1.5) &

                        (df['high_chg_atr1'] >= 0.3) &
                        (df['gap_atr1'] >= 0) &
                        (df['close_range1'] >= 0.3) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.5) &
                        (df['gap_atr'] >= 0.25) &
                        (df['close_range'] >= 0.3) &
                        (df['c'] >= df['o']) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_50ema_atr'] >= 4) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['h'] >= df['highest_high_250']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']) &
                        (df['ema50'] >= df['ema200']))

                        ).astype(int)
    df['lc_backside_d4_para'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['dist_h_9ema_atr2'] >= 1) &
                        (df['dist_h_9ema_atr3'] >= 1) &
                        (df['dist_h_9ema_atr4'] >= 1) &

                        (df['c2'] >= df['o2']) &
                        (df['dist_h_20ema_atr2'] >= 1.5) &

                        (df['high_chg_atr1'] >= 0.3) &
                        (df['gap_atr1'] >= 0) &
                        (df['close_range1'] >= 0.3) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 1.5) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.5) &
                        (df['gap_atr'] >= 0.25) &
                        (df['close_range'] >= 0.3) &
                        (df['c'] >= df['o']) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_50ema_atr'] >= 4) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['ema9'] < df['ema20']) |
                        (df['ema20'] < df['ema50']) |
                        (df['ema50'] < df['ema200']) |
                        (df['h'] < df['highest_high_250']))

                        ).astype(int)

    df['lc_frontside_d3_uptrend'] = ((df['h'] >= df['h1']) &
                        (df['h1'] >= df['h2']) &

                        (df['high_chg_atr1'] >= 0.3) &
                        (df['close_range1'] >= 0.5) &
                        (df['c1'] >= df['o1']) &
                        (df['dist_h_9ema_atr1'] >= 2) &
                        (df['dist_h_20ema_atr1'] >= 3) &

                        (df['high_chg_atr'] >= 0.5) &
                        (df['gap_atr'] >= -0.2) &
                        (df['close_range'] >= 0.5) &
                        (df['dist_h_9ema_atr'] >= 2) &
                        (df['dist_h_20ema_atr'] >= 3) &
                        (df['dist_h_200ema_atr'] >= 7) &
                        (df['v_ua'] >= 10000000) &
                        (df['dol_v'] >= 500000000) &
                        (df['c_ua'] >= 20) &

                        ((df['h'] >= df['highest_high_250']) &
                        (df['ema9'] >= df['ema20']) &
                        (df['ema20'] >= df['ema50']) &
                        (df['ema50'] >= df['ema200']))

                        ).astype(int)
    df['lc_backside_d3'] = ((df['h'] >= df['h1']) &
                            (df['h1'] >= df['h2']) &

                            (df['high_chg_atr1'] >= 1) &
                            (df['close_range1'] >= 0.5) &
                            (df['c1'] >= df['o1']) &
                            (df['dist_h_9ema_atr1'] >= 1) &
                            (df['dist_h_20ema_atr1'] >= 2) &

                            (df['high_chg_atr'] >= 1) &
                            (df['close_range'] >= 0.5) &
                            (df['dist_h_9ema_atr'] >= 1) &
                            (df['dist_h_20ema_atr'] >= 2) &
                            (df['v_ua'] >= 10000000) &
                            (df['dol_v'] >= 500000000) &
                            (df['c_ua'] >= 20) &

                            ((df['ema9'] < df['ema20']) |
                            (df['ema20'] < df['ema50']) |
                            (df['ema50'] < df['ema200']) |
                            (df['h'] < df['highest_high_250']))

                        ).astype(int)


    df['lc_frontside_d2_uptrend'] = ((df['high_chg_atr'] >= 0.75) &
                            (df['close_range'] >= 0.7) &
                            (df['c'] >= df['o']) &
                            (df['dist_h_9ema_atr'] >= 1.5) &
                            (df['dist_h_20ema_atr'] >= 3) &
                            (df['v_ua'] >= 10000000) &
                            (df['dol_v'] >= 500000000) &
                            (df['c_ua'] >= 2000000000) &
                            (df['h_dist_to_lowest_low_20_atr'] >= 5) &
                            (df['h'] >= df['highest_high_20']) &

                            ((df['h'] >= df['highest_high_250']) &
                            (df['ema9'] >= df['ema20']) &
                            (df['ema20'] >= df['ema50']) &
                            (df['ema50'] >= df['ema200']))

                            ).astype(int)
    df['lc_frontside_d2'] = ((df['high_chg_atr'] >= 1.5) &
                            (df['close_range'] >= 0.5) &
                            (df['c'] >= df['o']) &
                            (df['v_ua'] >= 10000000) &
                            (df['dol_v'] >= 500000000) &
                            (df['c_ua'] >= 20) &

                            ((df['h'] >= df['highest_high_250']) &
                            (df['ema9'] >= df['ema20']) &
                            (df['ema20'] >= df['ema50']) &
                            (df['ema50'] >= df['ema200']))

                            ).astype(int)
    df['lc_backside_d2'] = ((df['high_chg_atr'] >= 1.5) &
                            (df['close_range'] >= 0.5) &
                            (df['c'] >= df['o']) &
                            (df['v_ua'] >= 10000000) &
                            (df['dol_v'] >= 500000000) &
                            (df['c_ua'] >= 20) &
                            (df['h'] >= df['highest_high_5']) &

                            ((df['ema9'] < df['ema20']) |
                            (df['ema20'] < df['ema50']) |
                            (df['ema50'] < df['ema200']) |
                            (df['h'] < df['highest_high_250']))

                            ).astype(int)


    df['lc_fbo'] = (((df['high_chg_atr'] >= 0.5) | (df['high_chg_from_pdc_atr'] >= 0.5)) &
                    (df['h'] >= df['h1']) &
                    (df['close_range'] >= 0.3) &
                    (df['c'] >= df['o']) &
                    (df['v_ua'] >= 10000000) &
                    (df['dol_v'] >= 500000000) &
                    (df['c_ua'] >= 2000000000) &
                    ((df['h_dist_to_lowest_low_20_atr'] >= 4) | (df['h_dist_to_lowest_low_5_atr'] >= 2)) &
                    (df['h'] >= df['highest_high_50_4'] - df['atr']*1) &
                    (df['h'] <= df['highest_high_50_4'] + df['atr']*1) &

                    (df['highest_high_50_4'] >= df['highest_high_100_4']) &

                    (df['h1'] < df['highest_high_50_4']) &
                    (df['h2'] < df['highest_high_50_4']) &
                    (df['h3'] < df['highest_high_50_4']) &

                    (df['ema9'] >= df['ema20']) &
                    (df['ema20'] >= df['ema50']) &
                    (df['ema50'] >= df['ema200'])

                    ).astype(int)

    #'''



    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_frontside_d2_extended', 'lc_frontside_d2_extended_1']


    df2 = df[df[columns_to_check].any(axis=1)]
    return df2


def filter_lc_rows(df):

    return df[(df['lc_frontside_d3_extended_1'] == 1) | (df['lc_frontside_d2_extended'] == 1) | (df['lc_frontside_d2_extended_1'] == 1)]



async def fetch_intraday_data(session, ticker, start_date, end_date):
    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{start_date}/{end_date}'
    params = {'apiKey': API_KEY}
    async with session.get(url, params=params) as response:
        if response.status == 200:
            data = await response.json()
            return pd.DataFrame(data['results'])
        else:
            print(f"Failed to fetch data for {ticker}: {response.status}")
            return pd.DataFrame()


def get_min_price_lc(df):
    ### LC Min Price

    df['lc_frontside_d3_extended_1_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_backside_d3_extended_1_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_frontside_d3_extended_2_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_backside_d3_extended_2_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_frontside_d4_para_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_backside_d4_para_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_frontside_d3_uptrend_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_backside_d3_min_price'] = round((df['c'] + df['d1_range']*.3), 2)
    df['lc_frontside_d2_uptrend_min_price'] = round((df['c'] + df['d1_range']*.5), 2)
    df['lc_frontside_d2_min_price'] = round((df['c'] + df['d1_range']*.5), 2)
    df['lc_backside_d2_min_price'] = round((df['c'] + df['d1_range']*.5), 2)
    df['lc_fbo_min_price'] = round((df['c'] + df['d1_range']*.5), 2)



    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',
     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']

    df['lowest_min_price'] = df.apply(lambda row: min([row[col + '_min_price'] for col in columns_to_check if row[col] == 1]), axis=1)

    for col in columns_to_check:
        min_price_col = f"{col}_min_price"
        min_pct_col = f"{col}_min_pct"
        df[min_pct_col] = round((df[min_price_col] / df['c'] - 1) * 100, 2)


    return df


# OPTIMIZED FUNCTION WITH MAX WORKERS SEMAPHORE (ONLY CHANGE)
async def fetch_intial_stock_list(session, date, adj, semaphore):
    async with semaphore:  # Control concurrency
        url = f"https://api.polygon.io/v2/aggs/grouped/locale/us/market/stocks/{date}?adjusted={adj}&apiKey={API_KEY}"
        async with session.get(url) as response:
            if response.status == 200:
                data = await response.json()
                if 'results' in data:
                    df = pd.DataFrame(data['results'])
                    # df = df[(df['v_ua'] >= 2000000) & (df['c'] >= df['o']) & (df['c'] * df['v'] >= 20000000) & (((df['c'] * df['l']) / (df['h'] * df['l'])) >= 0.3)]
                    df['date'] = pd.to_datetime(df['t'], unit='ms').dt.date
                    df.rename(columns={'T': 'ticker'}, inplace=True)
                    # print(url)
                    return df



def compute_indicators1(df):
    # Sorting by 'ticker' and 'date' to respect chronological order for each ticker
    df = df.sort_values(by=['ticker', 'date'])

    # Calculating previous day's close
    df['pdc'] = df.groupby('ticker')['c'].shift(1)

    # Calculating ranges and true range
    df['high_low'] = df['h'] - df['l']
    df['high_pdc'] = (df['h'] - df['pdc']).abs()
    df['low_pdc'] = (df['l'] - df['pdc']).abs()
    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)
    df['atr'] = df.groupby('ticker')['true_range'].transform(lambda x: x.rolling(window=14).mean())

    df['atr'] = df['atr'].shift(1)

    # df['atr'] = df['atr'].fillna(0)
    # df['pdc'] = df['pdc'].fillna(0)

    df['d1_range'] = abs(df['h'] - df['l'])

    # Shifting values for high, close, open, low, volume
    for i in range(1, 4):
        df[f'h{i}'] = df.groupby('ticker')['h'].shift(i).fillna(0)
        # if i <= 2:  # Limiting to 2 days shift for close, open, low, volume
        df[f'c{i}'] = df.groupby('ticker')['c'].shift(i).fillna(0)
        df[f'o{i}'] = df.groupby('ticker')['o'].shift(i).fillna(0)
        df[f'l{i}'] = df.groupby('ticker')['l'].shift(i).fillna(0)
        df[f'v{i}'] = df.groupby('ticker')['v'].shift(i).fillna(0)

    # Dollar volume calculations and shifts
    df['dol_v'] = df['c'] * df['v']
    df['dol_v1'] = df.groupby('ticker')['dol_v'].shift(1)
    df['dol_v2'] = df.groupby('ticker')['dol_v'].shift(2)
    df['dol_v3'] = df.groupby('ticker')['dol_v'].shift(3)
    df['dol_v4'] = df.groupby('ticker')['dol_v'].shift(4)
    df['dol_v5'] = df.groupby('ticker')['dol_v'].shift(5)

    df['dol_v_cum5_1'] = df['dol_v1'] + df['dol_v2'] + df['dol_v3'] + df['dol_v3'] + df['dol_v5']

    # Close range calculations and shifts
    df['close_range'] = (df['c'] - df['l']) / (df['h'] - df['o'])
    df['close_range1'] = df.groupby('ticker')['close_range'].shift(1)
    df['close_range2'] = df.groupby('ticker')['close_range'].shift(2)

    # Days Range

    df['range'] = (df['h'] - df['l'])
    df['range1'] = df.groupby('ticker')['range'].shift(1)
    df['range2'] = df.groupby('ticker')['range'].shift(2)

    # Gap metrics related to ATR
    df['gap_pct'] = (df['o'] / df['pdc']) - 1
    df['gap_pct1'] = df.groupby('ticker')['gap_pct'].shift(1)
    df['gap_pct2'] = df.groupby('ticker')['gap_pct'].shift(2)
    df['gap_atr'] = ((df['o'] - df['pdc']) / df['atr'])
    df['gap_atr1'] = ((df['o1'] - df['c2']) / df['atr'])
    df['gap_atr2'] = ((df['o2'] - df['c3']) / df['atr'])
    df['gap_pdh_atr'] = ((df['o'] - df['h1']) / df['atr'])

    # High change metrics normalized by ATR
    df['pct_chg'] = (df['c'] / df['c1']) - 1
    df['high_pct_chg'] = (df['h'] / df['c1']) - 1
    df['pct_chg1'] = df.groupby('ticker')['pct_chg'].shift(1)
    df['high_pct_chg1'] = df.groupby('ticker')['high_pct_chg'].shift(1)
    df['high_pct_chg2'] = df.groupby('ticker')['high_pct_chg'].shift(2)

    df['high_chg'] = df['h'] - df['o']
    df['high_chg1'] = df['h1'] - df['o1']
    df['high_chg_atr'] = df['high_chg'] / df['atr']
    df['high_chg_atr1'] = ((df['h1'] - df['o1']) / df['atr'])
    df['high_chg_atr2'] = ((df['h2'] - df['o2']) / df['atr'])

    # High change from previous day close normalized by ATR
    df['high_chg_from_pdc_atr'] = ((df['h'] - df['c1']) / df['atr'])
    df['high_chg_from_pdc_atr1'] = ((df['h1'] - df['c2']) / df['atr'])

    # Percentage change in close price from the previous day
    df['pct_change'] = ((df['c'] / df['c1'] - 1) * 100).round(2)

    df['avg5_vol'] = df['v'].rolling(window=5).mean()
    df['rvol'] = df['v'] / df['avg5_vol']
    df['rvol1'] = df.groupby('ticker')['rvol'].shift(1)

    # Calculating EMAs
    for period in [9, 20, 50, 200]:
        df[f'ema{period}'] = df.groupby('ticker')['c'].transform(lambda x: x.ewm(span=period, adjust=False).mean().fillna(0))
        df[f'dist_h_{period}ema'] = df['h'] - df[f'ema{period}']
        df[f'dist_h_{period}ema_atr'] = df[f'dist_h_{period}ema'] / df['atr']

        df[f'dist_l_{period}ema'] = df['l'] - df[f'ema{period}']
        df[f'dist_l_{period}ema_atr'] = df[f'dist_l_{period}ema'] / df['atr']

        # Apply shifts to the calculated distances and normalize again by ATR
        for dist in range(1, 5):
            df[f'dist_h_{period}ema{dist}'] = df.groupby('ticker')[f'dist_h_{period}ema'].shift(dist)
            df[f'dist_h_{period}ema_atr{dist}'] = df[f'dist_h_{period}ema{dist}'] / df['atr']

            df[f'dist_l_{period}ema{dist}'] = df.groupby('ticker')[f'dist_l_{period}ema'].shift(dist)
            df[f'dist_l_{period}ema_atr{dist}'] = df[f'dist_l_{period}ema{dist}'] / df['atr']

    # Calculate rolling maximums and minimums
    for window in [5, 20, 50, 100, 250]:
        df[f'lowest_low_{window}'] = df.groupby('ticker')['l'].transform(lambda x: x.rolling(window=window, min_periods=1).min())
        df[f'highest_high_{window}'] = df.groupby('ticker')['h'].transform(lambda x: x.rolling(window=window, min_periods=1).max())

        # Shifting previous highs for selected windows
        for dist in range(1, 5):
            df[f'highest_high_{window}_{dist}'] = df.groupby('ticker')[f'highest_high_{window}'].shift(dist)

    # Calculate rolling minimums for the low prices with shifts
    df['lowest_low_30'] = df.groupby('ticker')['l'].transform(lambda x: x.rolling(window=30, min_periods=1).min())
    df['lowest_low_30_1'] = df.groupby('ticker')['lowest_low_30'].shift(1)

    # Calculate rolling maximums for high prices with multiple shifts
    df['highest_high_100_1'] = df.groupby('ticker')['highest_high_100'].shift(1)
    df['highest_high_100_4'] = df.groupby('ticker')['highest_high_100'].shift(4)
    df['highest_high_250_1'] = df.groupby('ticker')['highest_high_250'].shift(1)
    df['lowest_low_20_1'] = df.groupby('ticker')['lowest_low_20'].shift(1)
    df['lowest_low_20_2'] = df.groupby('ticker')['lowest_low_20'].shift(2)
    df['highest_high_20_1'] = df.groupby('ticker')['highest_high_20'].shift(1)
    df['highest_high_20_2'] = df.groupby('ticker')['highest_high_20'].shift(2)
    df['highest_high_5_1'] = df.groupby('ticker')['highest_high_5'].shift(1)

    # Assuming l_ua is a predefined column in your DataFrame
    df['lowest_low_20_ua'] = df.groupby('ticker')['l_ua'].transform(lambda x: x.rolling(window=20, min_periods=1).min())

    # Calculate distances from the lowest lows normalized by ATR
    df['h_dist_to_lowest_low_30'] = (df['h'] - df['lowest_low_30'])
    df['h_dist_to_lowest_low_30_atr'] = (df['h'] - df['lowest_low_30']) / df['atr']
    df['h_dist_to_lowest_low_20_atr'] = (df['h'] - df['lowest_low_20']) / df['atr']
    df['h_dist_to_lowest_low_5_atr'] = (df['h'] - df['lowest_low_5']) / df['atr']
    df['h_dist_to_highest_high_20_1_atr'] = (df['h'] - df['highest_high_20_1']) / df['atr']
    df['h_dist_to_highest_high_20_2_atr'] = (df['h'] - df['highest_high_20_2']) / df['atr']
    df['highest_high_5_dist_to_lowest_low_20_pct_1'] = (df['highest_high_5_1'] / df['lowest_low_20_1']) - 1
    df['h_dist_to_lowest_low_20_pct'] = (df['h'] / df['lowest_low_20']) - 1

    # Shifting EMAs
    df['ema20_2'] = df.groupby('ticker')['ema20'].shift(2)

    df['ema9_1'] = df['ema9'].shift(1)
    df['ema20_1'] = df['ema20'].shift(1)
    df['ema50_1'] = df['ema50'].shift(1)


    # df['ema9_1'] = df['ema9_1'].fillna(0)
    # df['ema20_1'] = df['ema20_1'].fillna(0)
    # df['ema50_1'] = df['ema50_1'].fillna(0)


    df['v_ua1'] = df.groupby('ticker')['v_ua'].shift(1)
    df['v_ua2'] = df.groupby('ticker')['v_ua'].shift(2)

    df['c_ua1'] = df['c_ua'].shift(1)


    # Drop intermediate columns
    columns_to_drop = ['high_low', 'high_pdc', 'low_pdc']
    df.drop(columns=columns_to_drop, inplace=True, errors='ignore')

    return df

def calculate_trading_days(date):
    # Define a range of trading days (30 days before and after the given date)
    start_date = date - pd.Timedelta(days=30)
    end_date = date + pd.Timedelta(days=30)

    # Get the trading schedule for the range
    schedule = nyse.schedule(start_date=start_date, end_date=end_date)
    trading_days = schedule.index

    # Ensure the date exists in the trading days
    if date not in trading_days:
        return pd.NaT, pd.NaT  # Return NaT if the date is not a trading day

    # Find the location of the given date in the trading days
    idx = trading_days.get_loc(date)

    # Calculate the next trading day and the fourth previous trading day
    date_plus_1 = trading_days[idx + 1] if idx + 1 < len(trading_days) else pd.NaT
    date_minus_4 = trading_days[idx - 4] if idx - 4 >= 0 else pd.NaT

    return date_plus_1, date_minus_4

def get_offsets(date):
    if date not in trading_days_map:
        return pd.NaT, pd.NaT
    idx = trading_days_map[date]
    date_plus_1 = trading_days_list[idx + 1] if idx + 1 < len(trading_days_list) else pd.NaT
    date_minus_4 = trading_days_list[idx - 4] if idx - 4 >= 0 else pd.NaT
    date_minus_30 = trading_days_list[idx - 30] if idx - 30 >= 0 else pd.NaT
    return date_plus_1, date_minus_4, date_minus_30




def fetch_intraday_data(ticker, start_date, end_date):
    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/30/minute/{start_date}/{end_date}?adjusted=true'
    params = {'apiKey': API_KEY}
    try:
        response = requests.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            if 'results' in data:
                return pd.DataFrame(data['results'])
            else:
                print(f"No results for {ticker}")
        else:
            print(f"Error fetching data for {ticker}: {response.status_code}")
    except Exception as e:
        print(f"Exception for {ticker}: {e}")
    return pd.DataFrame()



def process_lc_row(row):
    """Process a single row for intraday data and calculations."""
    try:
        ticker = row['ticker']
        date = row['date']

        date_minus_4 = row['date_minus_4']
        date_plus_1 = row['date_plus_1']

        # Fetch and adjust intraday data
        intraday_data = fetch_intraday_data(ticker, date_minus_4, date_plus_1)
        intraday_data = adjust_intraday(intraday_data)

        date_plus_1_formatted = datetime.datetime.strptime(date_plus_1, '%Y-%m-%d').date()

        intraday_data_before = intraday_data[intraday_data['date'] != date_plus_1_formatted]

        resp_v = intraday_data_before[intraday_data_before['time_int'] == 900].set_index('date')['v_sum']
        resp_o = intraday_data_before[intraday_data_before['time_int'] == 930].set_index('date')['o']
        resp_v, resp_o = resp_v.align(resp_o, fill_value=0)
        pm_dol_vol_all = resp_o * resp_v
        avg_pm_dol_vol = pm_dol_vol_all.mean()

        # Add results to row
        row['avg_5d_pm_dol_vol'] = avg_pm_dol_vol
        if avg_pm_dol_vol >= 10000000:
            row['valid_pm_liq'] = 1
        else:
            row['valid_pm_liq'] = 0
        # row['valid_pm_liq'] = 1 if avg_pm_dol_vol >= 10000000 else 0


        intraday_data_after = intraday_data[intraday_data['date'] == date_plus_1_formatted]


        pm_df = intraday_data_after[intraday_data_after['time_int'] <= 900].set_index('time')
        open_df = intraday_data_after[intraday_data_after['time_int'] <= 930].set_index('time')

        if not pm_df.empty:
            resp_v = pm_df['v_sum'][-1]
            resp_o = open_df['o'][-1]
            pm_dol_vol_next_day = resp_o * resp_v
            pmh_next_day = pm_df['hod_all'][-1]
        else:
            pm_dol_vol_next_day = 0
            pmh_next_day = 0
            resp_o = 0

        row['pmh_next_day'] = pmh_next_day
        row['open_next_day'] = resp_o
        row['pm_dol_vol_next_day'] = pm_dol_vol_next_day

    except Exception as e:
        print(f"Error processing LC Row {row['ticker']} on {row['date']}: {e}")
        row['avg_5d_pm_dol_vol'] = None
        row['valid_pm_liq'] = None
        row['pmh_next_day'] = 0
        row['open_next_day'] = 0
        row['pm_dol_vol_next_day'] = 0

    return row


def dates_before_after(df):
    global trading_days_map, trading_days_list

    start_date = df['date'].min() - pd.Timedelta(days=60)
    end_date = df['date'].max() + pd.Timedelta(days=30)
    schedule = nyse.schedule(start_date=start_date, end_date=end_date)
    trading_days = pd.Series(schedule.index, index=schedule.index)

    # Map trading days for faster lookup
    trading_days_list = trading_days.index.to_list()
    trading_days_map = {day: idx for idx, day in enumerate(trading_days_list)}

    results = df_lc['date'].map(get_offsets)
    df_lc[['date_plus_1', 'date_minus_4', 'date_minus_30']] = pd.DataFrame(results.tolist(), index=df_lc.index)

    # Format dates as strings if needed
    df_lc['date_plus_1'] = df_lc['date_plus_1'].dt.strftime('%Y-%m-%d')
    df_lc['date_minus_4'] = df_lc['date_minus_4'].dt.strftime('%Y-%m-%d')
    df_lc['date_minus_30'] = df_lc['date_minus_30'].dt.strftime('%Y-%m-%d')


    return df


def check_next_day_valid_lc(df):
    # Ensure minimum price columns exist for each check column

    columns_to_check = ['lc_backside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',
     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']

    for col in columns_to_check:
        min_price_col = col + '_min_price'
        if col in df.columns and min_price_col in df.columns:
            # Vectorized condition checks
            condition = (df[col] == 1) & (df['open_next_day'] >= df[min_price_col])
            df[col] = condition.astype(int)  # Update the column based on conditions

    df = df[~(df[columns_to_check] == 0).all(axis=1)]

    return df


def check_lc_pm_liquidity(df):
    df.loc[
        ((df['lc_frontside_d3_extended_1'] == 1) | (df['lc_backside_d3_extended_1'] == 1) | (df['lc_frontside_d3_extended_2'] == 1) | (df['lc_backside_d3_extended_2'] == 1) | (df['lc_frontside_d4_para'] == 1) | (df['lc_backside_d4_para'] == 1) |
         (df['lc_frontside_d3_uptrend'] == 1) | (df['lc_backside_d3'] == 1) | (df['lc_frontside_d2_uptrend'] == 1) | (df['lc_fbo'] == 1)) &
        (df['valid_pm_liq'] != 1),
        ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',
        'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_fbo']
        ] = 0

    df.loc[
        ((df['lc_frontside_d2'] == 1) | (df['lc_backside_d2'] == 1)) &
        (df['valid_pm_liq'] == 0),
        ['lc_frontside_d2', 'lc_backside_d2']
        ] = 0



    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',
     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']

    # Drop rows where all specified columns are 0
    df = df[~(df[columns_to_check] == 0).all(axis=1)]

    # df_lc = df_lc[df_lc['valid_pm_liq'] == 1]

    return df

def process_dataframe(func, data):
    with ProcessPoolExecutor(max_workers=cpu_count()) as executor:
        processed_rows = list(executor.map(func, data))
    return pd.DataFrame(processed_rows)


async def main():
    global df_lc, df_sc
    ### Get Main List
    all_results = []
    adj = "true"

    # CREATE SEMAPHORE FOR MAX WORKERS CONTROL WITH REDUCED CONCURRENCY
    # Semaphore limits concurrent operations to prevent resource exhaustion
    semaphore = asyncio.Semaphore(MAX_WORKERS)

    # Add memory management for large datasets
    import gc
    gc.collect()  # Force garbage collection before starting

    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
        tasks = [fetch_intial_stock_list(session, date, adj, semaphore) for date in DATES]  # Add semaphore
        # results = await asyncio.gather(*tasks)
        # all_results = [result for result in results if result is not None]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        # all_results = [result for result in results if isinstance(result, pd.DataFrame)]


        all_results = []
        retry_tasks = []

        # Check results and prepare for retry if necessary
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # print(f"Retrying failed task for date: {DATES[i]} due to {result}")
                retry_tasks.append(fetch_intial_stock_list(session, DATES[i], adj, semaphore))  # Add semaphore
            else:
                all_results.append(result)

        # Retry failed tasks
        if retry_tasks:
            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)
            # Merge retry results, assuming they are in the same order as retry_tasks
            for retry_result in retry_results:
                if not isinstance(retry_result, Exception):
                    all_results.append(retry_result)
                else:
                    print(f"Failed after retry: {retry_result}")



    df_a = pd.concat(all_results, ignore_index=True)
    all_results = []  # Clear for memory management
    gc.collect()  # Force garbage collection
    adj = "false"
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
        tasks = [fetch_intial_stock_list(session, date, adj, semaphore) for date in DATES]  # Add semaphore
        # results = await asyncio.gather(*tasks)
        # all_results = [result for result in results if result is not None]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        # all_results = [result for result in results if isinstance(result, pd.DataFrame)]


        all_results = []
        retry_tasks = []

        # Check results and prepare for retry if necessary
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                # print(f"Retrying failed task for date: {DATES[i]} due to {result}")
                retry_tasks.append(fetch_intial_stock_list(session, DATES[i], adj, semaphore))  # Add semaphore
            else:
                all_results.append(result)

        # Retry failed tasks
        if retry_tasks:
            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)
            # Merge retry results, assuming they are in the same order as retry_tasks
            for retry_result in retry_results:
                if not isinstance(retry_result, Exception):
                    all_results.append(retry_result)
                else:
                    print(f"Failed after retry: {retry_result}")


    df_ua = pd.concat(all_results, ignore_index=True)
    df_ua.rename(columns={col: col + '_ua' if col not in ['date', 'ticker'] else col for col in df_ua.columns}, inplace=True)

    # Clear memory after data processing
    all_results = []
    gc.collect()

    print("done 1")

    df = pd.merge(df_a, df_ua, on=['date', 'ticker'], how='inner')

    # Clear intermediate dataframes to save memory
    del df_a, df_ua
    gc.collect()

    df = df.drop(columns=['vw', 't', 'n', 'vw_ua', 't_ua', 'n_ua'])
    df = df.sort_values(by='date')

    df['date'] = pd.to_datetime(df['date'])

    print(df)
    print("done 2")



    df = df.select_dtypes(include=['floating']).round(2).join(df.select_dtypes(exclude=['floating']))



    df = compute_indicators1(df)
    df = df.sort_values(by='date')
    # df = df[df['pre_conditions'] == True]



    df = df.select_dtypes(include=['floating']).round(2).join(df.select_dtypes(exclude=['floating']))



    # df = df[(df['date'] >= START_DATE_DT) & (df['date'] <= END_DATE_DT)]
    # df = df.reset_index(drop=True)

    print(df)
    print("done 3")


    df_lc = check_high_lvl_filter_lc(df)

    '''

    df = dates_before_after(df)

    print("done 4")


    # df = df[(df['date'] >= start_date_70_days_before) & (df['date'] <= END_DATE_DT)]
    # df = df.reset_index(drop=True)



    rows_lc = df_lc.to_dict(orient='records')

    # Use ProcessPoolExecutor to process both dataframes concurrently
    with ProcessPoolExecutor() as executor:
        future_lc = executor.submit(process_dataframe, process_lc_row, rows_lc)

        df_lc = future_lc.result()

    print("done 5")

    # Continue with further processing
    df_lc = (df_lc)
    df_lc = check_next_day_valid_lc(df_lc)
    #'''

    df_lc = filter_lc_rows(df_lc)

    print("done 6")




    df_lc = df_lc[(df_lc['date'] >= START_DATE_DT) & (df_lc['date'] <= END_DATE_DT)]
    df_lc = df_lc.reset_index(drop=True)



    # Output the final dataframes
    # print(df_lc)
    print(df_lc[['date', 'ticker']])
    df_lc.to_csv("lc_backtest.csv")








if __name__ == "__main__":
    START_DATE = '2024-01-01'  # Specify the start date
    END_DATE = '2025-10-20'

    START_DATE_DT = pd.to_datetime(START_DATE)
    END_DATE_DT = pd.to_datetime(END_DATE)

    start_date_70_days_before = pd.Timestamp(START_DATE) - pd.DateOffset(days=70)
    start_date_70_days_before = pd.to_datetime(start_date_70_days_before)

    start_date_300_days_before = pd.Timestamp(START_DATE) - pd.DateOffset(days=400)
    start_date_300_days_before = str(start_date_300_days_before)[:10]

    schedule = nyse.schedule(start_date=start_date_300_days_before, end_date=END_DATE)
    DATES = nyse.valid_days(start_date=start_date_300_days_before, end_date=END_DATE)
    DATES = [date.strftime('%Y-%m-%d') for date in nyse.valid_days(start_date=start_date_300_days_before, end_date=END_DATE)]

if __name__ == "__main__":
    asyncio.run(main())
    # asyncio.run(main())

    print("Getting Stocks")

