{
  "code": "import pandas as pd\nimport requests\nimport time\nimport numpy as np\nimport pandas_market_calendars as mcal\nimport aiohttp\nimport asyncio\nimport pandas as pd\nfrom multiprocessing import Pool, cpu_count\nfrom concurrent.futures import ProcessPoolExecutor\nfrom tabulate import tabulate\nimport webbrowser\nimport plotly.graph_objects as go\nimport sys\nfrom concurrent.futures import ThreadPoolExecutor\nimport dask\nfrom dask.distributed import Client, as_completed\nimport dask.dataframe as dd\nimport datetime\nimport logging\nimport backoff\n\nnyse = mcal.get_calendar('NYSE')\nexecutor = ThreadPoolExecutor() \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nif sys.platform == 'win32':\n    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n\nDATE = \"2025-01-17\"\n\n\n# Replace with your Polygon API Key\nAPI_KEY = '4r6MZNWLy2ucmhVI7fY8MrvXfXTSmxpy'\nBASE_URL = \"https://api.polygon.io\"\n\n\n\ndef adjust_daily(df):\n    # df = pd.DataFrame(data)\n    df['date'] = pd.to_datetime(df['t'], unit='ms')\n    df['date'] = df['date'].dt.date          \n    df['pdc'] = df['c'].shift(1)\n    df['high_low'] = df['h'] - df['l']  # High - Low\n    df['high_pdc'] = abs(df['h'] - df['pdc'])  # High - Previous Day Close\n    df['low_pdc'] = abs(df['l'] - df['pdc'])  # Low - Previous Day Close\n    # True Range (TR) is the max of high-low, high-pdc, low-pdc\n    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)\n    # Calculate the ATR (using a 14-day rolling window)\n    df['atr'] = df['true_range'].rolling(window=14).mean()\n    # Drop intermediate columns for clean output\n    df.drop(['high_low', 'high_pdc', 'low_pdc'], axis=1, inplace=True)\n\n         \n    df['h1'] = df['h'].shift(1)\n    df['h2'] = df['h'].shift(2)\n    df['h3'] = df['h'].shift(3)\n\n    df['c1'] = df['c'].shift(1)\n    df['c2'] = df['c'].shift(2)\n    df['c3'] = df['c'].shift(3)\n\n    df['o1'] = df['o'].shift(1)\n    df['o2'] = df['o'].shift(2)\n    \n    df['l1'] = df['l'].shift(1)\n    df['l2'] = df['l'].shift(2)\n\n    df['v_ua1'] = df['v_ua'].shift(1)\n    df['v1'] = df['v'].shift(1)\n    df['v2'] = df['v'].shift(2)\n    \n    df['dol_v'] = (df['c'] * df['v'])\n    df['dol_v1'] = df['dol_v'].shift(1)\n    df['dol_v2'] = df['dol_v'].shift(2)\n\n\n    df['close_range'] = (df['c'] - df['l'])/(df['h'] - df['l'])\n    df['close_range1'] = df['close_range'].shift(1)\n    df['close_range2'] = df['close_range'].shift(2)\n\n    df['gap_atr'] = ((df['o'] - df['pdc'])/df['atr'])\n    df['gap_atr1'] = ((df['o1'] - df['c2'])/df['atr'])\n\n    df['gap_pdh_atr'] = ((df['o'] - df['h1'])/df['atr'])\n    \n    df['high_chg'] = (df['h'] - df['o'])\n    df['high_chg_atr'] = ((df['h'] - df['o'])/df['atr'])\n    # df['high_chg_atr'] = round(df['high_chg_atr'], 2)\n    df['high_chg_atr1'] = ((df['h1'] - df['o1'])/df['atr'])\n    df['high_chg_atr2'] = ((df['h2'] - df['o2'])/df['atr'])\n\n    df['high_chg_from_pdc_atr'] = ((df['h'] - df['c1'])/df['atr'])\n    df['high_chg_from_pdc_atr1'] = ((df['h1'] - df['c2'])/df['atr'])\n\n    df['pct_change'] = round(((df['c'] / df['c1']) - 1)*100, 2)\n    \n    df['ema9'] = df['c'].ewm(span=9, adjust=False).mean().fillna(0)\n    df['ema20'] = df['c'].ewm(span=20, adjust=False).mean().fillna(0)\n    df['ema50'] = df['c'].ewm(span=50, adjust=False).mean().fillna(0)\n    df['ema200'] = df['c'].ewm(span=200, adjust=False).mean().fillna(0)\n\n    df['ema20_2'] = df['ema20'].shift(2)\n\n    \n    df['ema9_1'] = df['ema9'].shift(1)\n    df['ema20_1'] = df['ema20'].shift(1)\n    df['ema50_1'] = df['ema50'].shift(1)\n    \n    df['dist_h_9ema'] = (df['h'] - df['ema9'])\n    df['dist_h_20ema'] = (df['h'] - df['ema20'])\n    df['dist_h_50ema'] = (df['h'] - df['ema50'])\n    df['dist_h_200ema'] = (df['h'] - df['ema200'])\n\n    df['dist_h_9ema1'] = df['dist_h_9ema'].shift(1)\n    df['dist_h_20ema1'] = df['dist_h_20ema'].shift(1)\n    df['dist_h_50ema1'] = df['dist_h_50ema'].shift(1)\n    df['dist_h_200ema1'] = df['dist_h_200ema'].shift(1)\n\n    df['dist_h_9ema_atr'] = df['dist_h_9ema'] /df['atr']\n    df['dist_h_20ema_atr'] = df['dist_h_20ema'] /df['atr']\n    df['dist_h_50ema_atr'] = df['dist_h_50ema'] /df['atr']\n    df['dist_h_200ema_atr'] = df['dist_h_200ema'] /df['atr']\n\n    df['dist_h_9ema_atr1'] = df['dist_h_9ema1'] /df['atr']\n    df['dist_h_20ema_atr1'] = df['dist_h_20ema1'] /df['atr']\n    df['dist_h_50ema_atr1'] = df['dist_h_50ema1'] /df['atr']\n    df['dist_h_200ema_atr1'] = df['dist_h_200ema1'] /df['atr']\n\n    df['dist_h_9ema2'] = df['dist_h_9ema'].shift(2)\n    df['dist_h_9ema3'] = df['dist_h_9ema'].shift(3)\n    df['dist_h_9ema4'] = df['dist_h_9ema'].shift(4)\n\n    df['dist_h_20ema2'] = df['dist_h_20ema'].shift(2)\n    df['dist_h_20ema3'] = df['dist_h_20ema'].shift(3)\n    df['dist_h_20ema4'] = df['dist_h_20ema'].shift(4)\n    df['dist_h_20ema5'] = df['dist_h_20ema'].shift(5)\n\n    df['dist_h_9ema_atr2'] = df['dist_h_9ema2'] /df['atr']\n    df['dist_h_9ema_atr3'] = df['dist_h_9ema3'] /df['atr']\n    df['dist_h_9ema_atr4'] = df['dist_h_9ema4'] /df['atr']\n    \n    df['dist_h_20ema_atr2'] = df['dist_h_20ema2'] /df['atr']\n    df['dist_h_20ema_atr3'] = df['dist_h_20ema3'] /df['atr']\n    df['dist_h_20ema_atr4'] = df['dist_h_20ema4'] /df['atr']\n\n    df['lowest_low_20'] = df['l'].rolling(window=20, min_periods=1).min()\n    df['lowest_low_20_2'] = df['lowest_low_20'].shift(2)\n    df['h_dist_to_lowest_low_20_atr'] = ((df['h'] - df['lowest_low_20'])/df['atr'])\n\n    df['lowest_low_30'] = df['l'].rolling(window=30, min_periods=1).min()\n    df['lowest_low_30_1'] = df['lowest_low_30'].shift(1)\n\n    df['h_dist_to_lowest_low_30'] = (df['h'] - df['lowest_low_30'])\n\n    df['lowest_low_5'] = df['l'].rolling(window=5, min_periods=1).min()\n    df['h_dist_to_lowest_low_5_atr'] = ((df['h'] - df['lowest_low_5'])/df['atr'])\n\n    df['highest_high_100'] = df['h'].rolling(window=100).max()\n    df['highest_high_100_1'] = df['highest_high_100'].shift(1)\n    \n    df['highest_high_250'] = df['h'].rolling(window=250, min_periods=1).max()\n    df['highest_high_250_1'] = df['highest_high_250'].shift(1)\n\n    df['highest_high_5'] = df['h'].rolling(window=5, min_periods=1).max()\n\n    df['highest_high_50'] = df['h'].rolling(window=50, min_periods=1).max()\n    df['highest_high_50_1'] = df['highest_high_50'].shift(1)\n    df['highest_high_50_4'] = df['highest_high_50'].shift(4)\n\n    df['highest_high_20'] = df['h'].rolling(window=20, min_periods=1).max()\n    df['highest_high_20_2'] = df['highest_high_20'].shift(2)\n\n    df['highest_high_100'] = df['h'].rolling(window=100, min_periods=1).max()\n    df['highest_high_100_4'] = df['highest_high_100'].shift(4)\n\n    return df\ndef adjust_intraday(df):\n    #df=pd.DataFrame(results)\n    df['date_time']=pd.to_datetime(df['t']*1000000).dt.tz_localize('UTC')\n    df['date_time']=df['date_time'].dt.tz_convert('US/Eastern')\n\n    #df['Date Time'] = pd.to_datetime(df['Date Time'])\n\n    # format the datetime objects to \"yyyy-mm-dd hh:mm:ss\" format\n    df['date_time'] = df['date_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n    df['date_time'] = pd.to_datetime(df['date_time'])\n\n    # df=df.set_index(['date_time']).asfreq('1min')\n    # df.v = df.v.fillna(0)\n    # df[['c']] = df[['c']].ffill()\n    # df['h'].fillna(df['c'], inplace=True)\n    # df['l'].fillna(df['c'], inplace=True)\n    # df['o'].fillna(df['c'], inplace=True)\n    # df=df.between_time('04:00', '20:00')\n    # df = df.reset_index(level=0)\n\n    df['time'] = pd.to_datetime(df['date_time']).dt.time\n    df['date'] = pd.to_datetime(df['date_time']).dt.date\n\n    # daily_v_sum = df.groupby(df['date_time'].dt.date)['v'].sum()\n    # valid_dates = daily_v_sum[daily_v_sum > 0].index\n    # df = df[df['date_time'].dt.date.isin(valid_dates)]\n    # # df = df.reset_index(level=0)\n    # df = df.reset_index(drop=True)\n\n    \n\n    df['time_int'] = df['date_time'].dt.hour * 100 + df['date_time'].dt.minute\n    df['date_int'] = df['date_time'].dt.strftime('%Y%m%d').astype(int)\n\n    \n    \n    df['date_time_int'] = df['date_int'].astype(str) + '.' + df['time_int'].astype(str)\n    df['date_time_int'] = df['date_time_int'].astype(float)\n\n    \n    df['v_sum'] = df.groupby('date')['v'].cumsum()\n    \n    df['hod_all'] = df.groupby(df['date'])['h'].cummax().fillna(0)\n\n    \n\n    return df\n\ndef check_high_lvl_filter_lc(df):\n\n    '''\n    # df = df1.iloc[-1]\n    # df = df1.tail(1)\n\n    ### SCORE\n    # 1. Atr exp: 20\n    # 2. EMA Dist: 30\n    # 3. Multi-day Burst: 20\n    # 4. Vol exp: 10\n    # 5. Gaps between: 20\n\n    # Total Score: 100\n\n    # ======================================================================\n    # 1) ATR Expansion score (weight target ~20 pts)\n    #    Prefer your normalized multiple if you have it: high_chg_atr1 (\u2248 (high-low)/ATR or similar).\n    # ======================================================================\n    atr_mult = df.get('high_chg_atr1', 0.0)\n\n    df['score_atr'] = np.select(\n        [\n            atr_mult >= 3,\n            (atr_mult >= 2) & (atr_mult < 3),\n            (atr_mult >= 1) & (atr_mult < 2),\n            (atr_mult >= 0.5) & (atr_mult < 1),\n        ],\n        [20, 18, 15, 12],\n        default=0\n    )\n\n\n    # ======================================================================\n    # 2) EMA Distance score (weight target ~30 pts)\n    #    Use your ATR-normalized deviations; prefer 20EMA if available, else 9EMA.\n    # ======================================================================\n    ema_dev = np.where(df.get('dist_h_9ema_atr1', np.nan).astype(float) > 0,\n                    df['dist_h_9ema_atr1'],\n                    df.get('dist_9ema_atr1', 0.0))\n\n    df['score_ema'] = np.select(\n        [\n            ema_dev >= 4.0,\n            (ema_dev >= 3.0) & (ema_dev < 4.0),\n            (ema_dev >= 2.0) & (ema_dev < 3.0),\n            (ema_dev >= 1.0) & (ema_dev < 2.0),\n        ],\n        [30, 25, 20, 15],\n        default=0\n    )\n\n\n\n    # ======================================================================\n    # 3) Multi-Day Burst score (weight target ~25 pts)\n    #    Quantifies: consecutive up days + range expansion + at least one gap\n    #    - up_streak: consecutive closes > prev close\n    #    - range_exp_count: how many recent days expanded range vs prior\n    #    - has_gap: gap \u2265 3% today (you can extend to prior days if you track gap_pct_1, gap_pct_2, ...)\n    # ======================================================================\n    # up_streak (vectorized 3-day check using your lagged closes if present)\n    has_c2 = 'c2' in df.columns\n    has_c3 = 'c3' in df.columns\n\n    up1 = ((df['c1'] > df['c2'])&(df['c1'] > df['o1'])&(df['h1'] > df['h2'])).astype(int) if has_c2 else 0\n    up2 = ((df['c2'] > df['c3'])&(df['c2'] > df['o2'])&(df['h2'] > df['h3'])).astype(int) if (has_c2 and has_c3) else 0\n    # crude consecutive count over last 3 bars (today vs yesterday, yesterday vs day before)\n    up_streak3 = up1 + up2  # yields 0,1,2 (treat 2 as 3+ for scoring tiers below)\n\n    # range expansion: compare today vs yesterday; if you also have range2 vs range3, add it\n    has_range2 = 'range2' in df.columns\n    rng_today = df.get('range1', 0.0)\n    rng_yday  = df.get('range2', 0.0) if has_range2 else 0.0\n    rng_yday_atr = df.get('high_chg_atr2', 0.0)\n    range_exp1 = ((rng_today > rng_yday) & (rng_yday_atr>=0.5)).astype(int)\n    range_exp_count = range_exp1  # extend with more lags if you maintain them\n\n    # gap today\n    has_gap = (df.get('gap_atr1', 0.0) >= 0.3).astype(int)\n\n    # assemble a tiered burst score\n    df['score_burst'] = np.select(\n        [\n            (up_streak3 >= 2) & (range_exp_count >= 1) & (has_gap == 1),   # ~3+ up days feel (2 comparisons true), 1+ range expansion, gap\n            (up_streak3 >= 2) & (range_exp_count >= 1),\n            (up_streak3 >= 2),\n            (up_streak3 == 1) & (range_exp_count >= 1) & (has_gap == 1),\n            (up_streak3 == 1),\n        ],\n        [20, 17.5, 15, 12.5, 10],\n        default=10  # minimal burst evidence\n    )\n\n\n\n    # ======================================================================\n    # 4) Volume / RVOL score (weight target ~15 pts)\n    #    If you have rvol1 use it; else proxy with dollar volume tiers.\n    # ======================================================================\n    rvol = df.get('rvol1', np.nan).astype(float)\n    has_rvol = np.isfinite(rvol)\n\n    df['score_vol'] = np.select(\n        [\n            rvol >= 2,\n            (rvol >= 1.5) & (rvol < 2),\n            (rvol >= 1) & (rvol < 1.5),\n            (rvol >= 0.5) & (rvol < 1),\n        ],\n        [10, 8, 5, 2],\n        default=0\n    )\n\n\n    # ======================================================================\n    # 5) Gap Behavior score (weight target ~10 pts)\n    #    Uses your existing gap_pct (today vs yesterday).\n    #    If you maintain prior gap columns (gap_pct_1, gap_pct_2) you can add a consecutive gap bonus.\n    # ======================================================================\n    gap = df.get('gap_atr1', 0.0)\n\n    df['score_gap'] = np.select(\n        [\n            gap >= 0.5,\n            (gap >= 0.3) & (gap < 0.5),\n            (gap >= 0.1) & (gap < 0.3),\n        ],\n        [15, 10, 5],\n        default=0\n    )\n\n    # Optional: consecutive gap bonus if you track gap_pct_1 / gap_pct_2, etc.\n    if 'gap_atr2' in df.columns:\n        consec_gaps = ((df['gap_atr1'] >= 0.3) & (df['gap_atr2'] >= 0.3)).astype(int)\n        df['score_gap'] = df['score_gap'] + consec_gaps * 5  # max bonus +5\n\n\n\n    df['parabolic_score_raw'] = (\n        df['score_atr'] + df['score_ema'] + df['score_burst'] +\n        df['score_vol'] + df['score_gap']\n    )\n\n    df['parabolic_score'] = df['parabolic_score_raw'].clip(upper=100)\n\n\n    # Optional tiers for quick filtering\n    df['parabolic_tier'] = np.select(\n        [\n            df['parabolic_score'] >= 90,\n            (df['parabolic_score'] >= 75) & (df['parabolic_score'] < 90),\n            (df['parabolic_score'] >= 60) & (df['parabolic_score'] < 75),\n            (df['parabolic_score'] >= 40) & (df['parabolic_score'] < 60),\n        ],\n        ['A+','A','B','C'],\n        default='D'\n    )\n\n    # Example hard filters to keep only prime watchlist names (tune as desired)\n    df['parabolic_watch'] = (\n        (df['c_ua'] >= 10) &    \n        (df['gap_atr'] >= 0.3) &    \n        (df['parabolic_score'] >= 60) &      # strong close near highs\n        (df['close_range1'] >= 0.25) &     \n        (df['c1'] > df['o1']) &       \n        (df['v_ua1'] >= 10000000)  &      \n        (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |\n        ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |\n        ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |\n        ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |\n        ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) & \n        (df['ema9_1'] >= df['ema20_1'])  &     \n        (df['ema20_1'] >= df['ema50_1'])  &     \n        (df['dol_v1'] >= 500000000)         # liquidity guardrail\n    ).astype(int)\n\n    #'''\n\n\n    '''\n    df['lc_d2'] = (\n                    (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |\n                     ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |\n                     ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &\n                    (df['v_ua1'] >= 10000000) & \n                    (df['dol_v1'] >= 500000000) & \n                    (df['close_range1'] >= .6) &\n                    (df['c1'] > df['o1']) & \n                    (df['h1'] > df['h2']) &\n                    (df['high_chg_atr1'] >= 2)).astype(int)\n    df['lc_d2_1'] = (\n                    (((df['high_pct_chg1'] >= .5) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |\n                     ((df['high_pct_chg1'] >= .25) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |\n                     ((df['high_pct_chg1'] >= .15) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .1) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .05) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &\n                    (df['v_ua1'] >= 10000000) & \n                    (df['dol_v1'] >= 500000000) & \n                    (df['close_range1'] >= .6) &\n                    (df['c1'] > df['o1']) & \n                    (df['h1'] > df['h2']) &\n                    (df['dist_h_9ema_atr1'] >= 2) & \n                    (df['high_chg_atr1'] >= 1.5)).astype(int)\n    \n\n    df['lc_d3'] = (\n                    (((df['high_pct_chg1'] >= .3) & (df['high_pct_chg2'] >= .3) & (df['c_ua1'] >= 5) & (df['c_ua1'] < 15) & (df['gap_pct'] >=  .15)) |\n                     ((df['high_pct_chg1'] >= .15) & (df['high_pct_chg2'] >= .15) & (df['c_ua1'] >= 15) & (df['c_ua1'] < 25) & (df['gap_pct'] >=  .1)) |\n                     ((df['high_pct_chg1'] >= .1) & (df['high_pct_chg2'] >= .1) & (df['c_ua1'] >= 25) & (df['c_ua1'] < 50) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .06) & (df['high_pct_chg2'] >= .06) & (df['c_ua1'] >= 50) & (df['c_ua1'] < 90) & (df['gap_pct'] >=  .05)) |\n                     ((df['high_pct_chg1'] >= .03) & (df['high_pct_chg2'] >= .03) & (df['c_ua1'] >= 90) & (df['gap_pct'] >=  .03))) &\n                    (df['v_ua1'] >= 10000000) & \n                    (df['dol_v1'] >= 500000000) & \n                    (df['v_ua2'] >= 10000000) & \n                    (df['dol_v2'] >= 500000000) & \n                    (df['close_range1'] >= .2) &\n                    (df['close_range2'] >= .5) &\n                    (df['c1'] > df['o1']) & \n                    (df['c2'] > df['o2']) & \n                    (df['h1'] > df['h2']) &\n                    (df['h2'] > df['h3']) &\n                    (df['high_chg_atr1'] >= 0.5) &\n                    (df['high_chg_atr2'] >= 0.5)).astype(int)\n\n\n    #'''\n\n\n\n    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n                        \n                        (df['l'] >= df['l1']) & \n                        (df['l1'] >= df['l2']) & \n\n                        (((df['high_pct_chg1'] >= .3) & (df['high_pct_chg'] >= .3) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['h_dist_to_lowest_low_20_pct']>=2.5)) |# & (df['gap_pct'] >=  .15)) |\n                        ((df['high_pct_chg1'] >= .2) & (df['high_pct_chg'] >= .2) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['h_dist_to_lowest_low_20_pct']>=2)) |# & (df['gap_pct'] >=  .1)) |\n                        ((df['high_pct_chg1'] >= .1) & (df['high_pct_chg'] >= .1) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['h_dist_to_lowest_low_20_pct']>=1.5)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg1'] >= .07) & (df['high_pct_chg'] >= .07) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['h_dist_to_lowest_low_20_pct']>=1)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg1'] >= .05) & (df['high_pct_chg'] >= .05) & (df['c_ua'] >= 90) & (df['h_dist_to_lowest_low_20_pct']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &\n                        \n\n                        (df['high_chg_atr1'] >= 0.7) & \n                        # (df['gap_atr1'] >= 0.2) & \n                        # (df['close_range1'] >= 0.6) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 2) & \n\n                        (df['high_chg_atr'] >= 1) &                  \n                        (df['c'] >= df['o']) & \n                        # (df['gap_atr'] >= 0.2) & \n                        # (df['close_range'] >= 0.6) & \n                        (df['dist_h_9ema_atr'] >= 1.5) & \n                        (df['dist_h_20ema_atr'] >= 2) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['v_ua1'] >= 10000000) & \n                        (df['dol_v1'] >= 100000000) & \n                        (df['c_ua'] >= 5) & \n\n                        \n                        ((df['high_chg_atr'] >= 1) | (df['high_chg_atr1'] >= 1))& \n\n                        (df['h_dist_to_highest_high_20_2_atr']>=2.5)&\n\n                        ((df['h'] >= df['highest_high_20']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']))\n                        \n                        ).astype(int)\n\n    df['lc_frontside_d2_extended'] = ((df['h'] >= df['h1']) & \n\n                        (df['l'] >= df['l1']) & \n\n\n                        (((df['high_pct_chg'] >= .5) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2.5)) |# & (df['gap_pct'] >=  .15)) |\n                        ((df['high_pct_chg'] >= .3) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2)) |# & (df['gap_pct'] >=  .1)) |\n                        ((df['high_pct_chg'] >= .2) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1.5)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg'] >= .15) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg'] >= .1) & (df['c_ua'] >= 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &\n                        \n\n\n\n                        (df['high_chg_atr'] >= 1.5) &               \n                        (df['c'] >= df['o']) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_20ema_atr'] >= 3) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 5) & \n\n                        (df['dist_l_9ema_atr'] >= 1) & \n                        \n                        (df['h_dist_to_highest_high_20_1_atr']>=1)&\n\n                        (df['dol_v_cum5_1']>=500000000)&\n                        \n\n                        ((df['h'] >= df['highest_high_20']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']))\n                        \n                        ).astype(int)\n\n\n    df['lc_frontside_d2_extended_1'] = ((df['h'] >= df['h1']) & \n\n                        (df['l'] >= df['l1']) & \n\n\n                        (((df['high_pct_chg'] >= 1) & (df['c_ua'] >= 5) & (df['c_ua'] < 15) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2.5)) |# & (df['gap_pct'] >=  .15)) |\n                        ((df['high_pct_chg'] >= .5) & (df['c_ua'] >= 15) & (df['c_ua'] < 25) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=2)) |# & (df['gap_pct'] >=  .1)) |\n                        ((df['high_pct_chg'] >= .3) & (df['c_ua'] >= 25) & (df['c_ua'] < 50) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1.5)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg'] >= .2) & (df['c_ua'] >= 50) & (df['c_ua'] < 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=1)) |# & (df['gap_pct'] >=  .05)) |\n                        ((df['high_pct_chg'] >= .15) & (df['c_ua'] >= 90) & (df['highest_high_5_dist_to_lowest_low_20_pct_1']>=0.75)))  & # & (df['gap_pct'] >=  .03))) &\n                        \n\n\n\n                        (df['high_chg_atr'] >= 1.5) &               \n                        (df['c'] >= df['o']) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_20ema_atr'] >= 3) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 5) & \n\n                        # (df['dist_l_9ema_atr'] >= 1) & \n                        \n                        (df['h_dist_to_highest_high_20_1_atr']>=1)&\n\n                        (df['dol_v_cum5_1']>=500000000)&\n                        \n\n                        ((df['h'] >= df['highest_high_20']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']))\n                        \n                        ).astype(int)\n\n    '''\n\n    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['pct_cng'] >= 0.5) & \n\n                        (df['high_chg_atr1'] >= 0.5) & \n                        (df['gap_atr1'] >= 0.2) & \n                        (df['close_range1'] >= 0.6) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.7) & \n                        (df['gap_atr'] >= 0.2) & \n                        (df['close_range'] >= 0.6) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_50ema_atr'] >= 4) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['h'] >= df['highest_high_250']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']) & \n                        (df['ema50'] >= df['ema200']))\n                        \n                        ).astype(int)\n    \n\n\n    df['lc_frontside_d3_extended_1'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['high_chg_atr1'] >= 0.5) & \n                        (df['gap_atr1'] >= 0.2) & \n                        (df['close_range1'] >= 0.6) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.7) & \n                        (df['gap_atr'] >= 0.2) & \n                        (df['close_range'] >= 0.6) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_50ema_atr'] >= 4) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['h'] >= df['highest_high_250']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']) & \n                        (df['ema50'] >= df['ema200']))\n                        \n                        ).astype(int)\n    df['lc_backside_d3_extended_1'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['high_chg_atr1'] >= 0.5) & \n                        (df['gap_atr1'] >= 0.2) & \n                        (df['close_range1'] >= 0.6) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.7) & \n                        (df['gap_atr'] >= 0.2) & \n                        (df['close_range'] >= 0.6) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_50ema_atr'] >= 4) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['ema9'] < df['ema20']) | \n                        (df['ema20'] < df['ema50']) | \n                        (df['ema50'] < df['ema200']) |\n                        (df['h'] < df['highest_high_250']))\n                                                \n                        ).astype(int)\n    \n    df['lc_frontside_d3_extended_2'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['high_chg_atr1'] >= 0.3) & \n                        (df['close_range1'] >= 0.5) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1) &                     \n                        (df['high_chg1'] >= df['high_chg']*0.4) & \n\n                        (df['high_chg_atr'] >= 0.6) & \n                        (df['gap_atr'] >= 0.2) & \n                        (df['close_range'] >= 0.4) & \n                        (df['dist_h_9ema_atr'] >= 1.5) & \n                        (df['dist_h_20ema_atr'] >= 3) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['h'] >= df['highest_high_250']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']) & \n                        (df['ema50'] >= df['ema200']))\n                        \n                        ).astype(int)  \n    df['lc_backside_d3_extended_2'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['high_chg_atr1'] >= 0.3) & \n                        (df['close_range1'] >= 0.5) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1) &                     \n                        (df['high_chg1'] >= df['high_chg']*0.4) & \n\n                        (df['high_chg_atr'] >= 0.6) & \n                        (df['gap_atr'] >= 0.2) & \n                        (df['close_range'] >= 0.4) & \n                        (df['dist_h_9ema_atr'] >= 1.5) & \n                        (df['dist_h_20ema_atr'] >= 3) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['ema9'] < df['ema20']) | \n                        (df['ema20'] < df['ema50']) | \n                        (df['ema50'] < df['ema200']) |\n                        (df['h'] < df['highest_high_250']))\n                        \n                        ).astype(int)\n    \n    df['lc_frontside_d4_para'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n                        \n                        (df['dist_h_9ema_atr2'] >= 1) & \n                        (df['dist_h_9ema_atr3'] >= 1) & \n                        (df['dist_h_9ema_atr4'] >= 1) & \n                        \n                        (df['c2'] >= df['o2']) & \n                        (df['dist_h_20ema_atr2'] >= 1.5) & \n\n                        (df['high_chg_atr1'] >= 0.3) & \n                        (df['gap_atr1'] >= 0) & \n                        (df['close_range1'] >= 0.3) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.5) & \n                        (df['gap_atr'] >= 0.25) & \n                        (df['close_range'] >= 0.3) &                   \n                        (df['c'] >= df['o']) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_50ema_atr'] >= 4) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['h'] >= df['highest_high_250']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']) & \n                        (df['ema50'] >= df['ema200']))\n                        \n                        ).astype(int)       \n    df['lc_backside_d4_para'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n                        \n                        (df['dist_h_9ema_atr2'] >= 1) & \n                        (df['dist_h_9ema_atr3'] >= 1) & \n                        (df['dist_h_9ema_atr4'] >= 1) & \n                        \n                        (df['c2'] >= df['o2']) & \n                        (df['dist_h_20ema_atr2'] >= 1.5) & \n\n                        (df['high_chg_atr1'] >= 0.3) & \n                        (df['gap_atr1'] >= 0) & \n                        (df['close_range1'] >= 0.3) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 1.5) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.5) & \n                        (df['gap_atr'] >= 0.25) & \n                        (df['close_range'] >= 0.3) &                   \n                        (df['c'] >= df['o']) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_50ema_atr'] >= 4) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['ema9'] < df['ema20']) | \n                        (df['ema20'] < df['ema50']) | \n                        (df['ema50'] < df['ema200']) |\n                        (df['h'] < df['highest_high_250']))\n                        \n                        ).astype(int)\n\n    df['lc_frontside_d3_uptrend'] = ((df['h'] >= df['h1']) & \n                        (df['h1'] >= df['h2']) & \n\n                        (df['high_chg_atr1'] >= 0.3) & \n                        (df['close_range1'] >= 0.5) &                  \n                        (df['c1'] >= df['o1']) & \n                        (df['dist_h_9ema_atr1'] >= 2) & \n                        (df['dist_h_20ema_atr1'] >= 3) & \n\n                        (df['high_chg_atr'] >= 0.5) & \n                        (df['gap_atr'] >= -0.2) & \n                        (df['close_range'] >= 0.5) & \n                        (df['dist_h_9ema_atr'] >= 2) & \n                        (df['dist_h_20ema_atr'] >= 3) & \n                        (df['dist_h_200ema_atr'] >= 7) & \n                        (df['v_ua'] >= 10000000) & \n                        (df['dol_v'] >= 500000000) & \n                        (df['c_ua'] >= 20) & \n\n                        ((df['h'] >= df['highest_high_250']) &\n                        (df['ema9'] >= df['ema20']) & \n                        (df['ema20'] >= df['ema50']) & \n                        (df['ema50'] >= df['ema200']))\n                        \n                        ).astype(int)         \n    df['lc_backside_d3'] = ((df['h'] >= df['h1']) & \n                            (df['h1'] >= df['h2']) & \n\n                            (df['high_chg_atr1'] >= 1) & \n                            (df['close_range1'] >= 0.5) &                  \n                            (df['c1'] >= df['o1']) & \n                            (df['dist_h_9ema_atr1'] >= 1) & \n                            (df['dist_h_20ema_atr1'] >= 2) & \n\n                            (df['high_chg_atr'] >= 1) & \n                            (df['close_range'] >= 0.5) & \n                            (df['dist_h_9ema_atr'] >= 1) & \n                            (df['dist_h_20ema_atr'] >= 2) & \n                            (df['v_ua'] >= 10000000) & \n                            (df['dol_v'] >= 500000000) & \n                            (df['c_ua'] >= 20) & \n\n                            ((df['ema9'] < df['ema20']) | \n                            (df['ema20'] < df['ema50']) | \n                            (df['ema50'] < df['ema200']) |\n                            (df['h'] < df['highest_high_250']))\n                                    \n                        ).astype(int)\n\n    \n    df['lc_frontside_d2_uptrend'] = ((df['high_chg_atr'] >= 0.75) & \n                            (df['close_range'] >= 0.7) &           \n                            (df['c'] >= df['o']) & \n                            (df['dist_h_9ema_atr'] >= 1.5) & \n                            (df['dist_h_20ema_atr'] >= 3) & \n                            (df['v_ua'] >= 10000000) & \n                            (df['dol_v'] >= 500000000) & \n                            (df['c_ua'] >= 2000000000) & \n                            (df['h_dist_to_lowest_low_20_atr'] >= 5) & \n                            (df['h'] >= df['highest_high_20']) &\n\n                            ((df['h'] >= df['highest_high_250']) &\n                            (df['ema9'] >= df['ema20']) & \n                            (df['ema20'] >= df['ema50']) & \n                            (df['ema50'] >= df['ema200']))\n                            \n                            ).astype(int)        \n    df['lc_frontside_d2'] = ((df['high_chg_atr'] >= 1.5) & \n                            (df['close_range'] >= 0.5) &                   \n                            (df['c'] >= df['o']) & \n                            (df['v_ua'] >= 10000000) & \n                            (df['dol_v'] >= 500000000) & \n                            (df['c_ua'] >= 20) & \n\n                            ((df['h'] >= df['highest_high_250']) &\n                            (df['ema9'] >= df['ema20']) & \n                            (df['ema20'] >= df['ema50']) & \n                            (df['ema50'] >= df['ema200']))\n\n                            ).astype(int)\n    df['lc_backside_d2'] = ((df['high_chg_atr'] >= 1.5) & \n                            (df['close_range'] >= 0.5) &           \n                            (df['c'] >= df['o']) & \n                            (df['v_ua'] >= 10000000) & \n                            (df['dol_v'] >= 500000000) & \n                            (df['c_ua'] >= 20) & \n                            (df['h'] >= df['highest_high_5']) &\n\n                            ((df['ema9'] < df['ema20']) | \n                            (df['ema20'] < df['ema50']) | \n                            (df['ema50'] < df['ema200']) |\n                            (df['h'] < df['highest_high_250']))\n                            \n                            ).astype(int)\n    \n    \n    df['lc_fbo'] = (((df['high_chg_atr'] >= 0.5) | (df['high_chg_from_pdc_atr'] >= 0.5)) & \n                    (df['h'] >= df['h1']) & \n                    (df['close_range'] >= 0.3) &           \n                    (df['c'] >= df['o']) & \n                    (df['v_ua'] >= 10000000) & \n                    (df['dol_v'] >= 500000000) & \n                    (df['c_ua'] >= 2000000000) & \n                    ((df['h_dist_to_lowest_low_20_atr'] >= 4) | (df['h_dist_to_lowest_low_5_atr'] >= 2)) & \n                    (df['h'] >= df['highest_high_50_4'] - df['atr']*1) & \n                    (df['h'] <= df['highest_high_50_4'] + df['atr']*1) & \n                    \n                    (df['highest_high_50_4'] >= df['highest_high_100_4']) & \n\n                    (df['h1'] < df['highest_high_50_4']) & \n                    (df['h2'] < df['highest_high_50_4']) & \n                    (df['h3'] < df['highest_high_50_4']) & \n\n                    (df['ema9'] >= df['ema20']) & \n                    (df['ema20'] >= df['ema50']) & \n                    (df['ema50'] >= df['ema200'])\n                    \n                    ).astype(int)\n\n    #'''\n\n   \n\n    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_frontside_d2_extended', 'lc_frontside_d2_extended_1']\n\n\n    df2 = df[df[columns_to_check].any(axis=1)]\n    return df2 \n\n\ndef filter_lc_rows(df):\n    \n    return df[(df['lc_frontside_d3_extended_1'] == 1) | (df['lc_frontside_d2_extended'] == 1) | (df['lc_frontside_d2_extended_1'] == 1)]\n\n\n\nasync def fetch_intraday_data(session, ticker, start_date, end_date):\n    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{start_date}/{end_date}'\n    params = {'apiKey': API_KEY}\n    async with session.get(url, params=params) as response:\n        if response.status == 200:\n            data = await response.json()\n            return pd.DataFrame(data['results'])\n        else:\n            print(f\"Failed to fetch data for {ticker}: {response.status}\")\n            return pd.DataFrame()\n        \n\ndef get_min_price_lc(df):\n    ### LC Min Price\n\n    df['lc_frontside_d3_extended_1_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_backside_d3_extended_1_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_frontside_d3_extended_2_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_backside_d3_extended_2_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_frontside_d4_para_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_backside_d4_para_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_frontside_d3_uptrend_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_backside_d3_min_price'] = round((df['c'] + df['d1_range']*.3), 2)\n    df['lc_frontside_d2_uptrend_min_price'] = round((df['c'] + df['d1_range']*.5), 2)\n    df['lc_frontside_d2_min_price'] = round((df['c'] + df['d1_range']*.5), 2)\n    df['lc_backside_d2_min_price'] = round((df['c'] + df['d1_range']*.5), 2)\n    df['lc_fbo_min_price'] = round((df['c'] + df['d1_range']*.5), 2)\n\n    \n\n    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',\n     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']\n\n    df['lowest_min_price'] = df.apply(lambda row: min([row[col + '_min_price'] for col in columns_to_check if row[col] == 1]), axis=1)\n\n    for col in columns_to_check:\n        min_price_col = f\"{col}_min_price\"\n        min_pct_col = f\"{col}_min_pct\"\n        df[min_pct_col] = round((df[min_price_col] / df['c'] - 1) * 100, 2)\n\n\n    return df\n\n\n\nasync def fetch_intial_stock_list(session, date, adj):\n    url = f\"https://api.polygon.io/v2/aggs/grouped/locale/us/market/stocks/{date}?adjusted={adj}&apiKey={API_KEY}\"\n    async with session.get(url) as response:\n        if response.status == 200:\n            data = await response.json()\n            if 'results' in data:\n                df = pd.DataFrame(data['results'])\n                # df = df[(df['v_ua'] >= 2000000) & (df['c'] >= df['o']) & (df['c'] * df['v'] >= 20000000) & (((df['c'] * df['l']) / (df['h'] * df['l'])) >= 0.3)]\n                df['date'] = pd.to_datetime(df['t'], unit='ms').dt.date\n                df.rename(columns={'T': 'ticker'}, inplace=True)\n                # print(url)\n                return df\n\n\n\n\ndef compute_indicators1(df):\n    # Sorting by 'ticker' and 'date' to respect chronological order for each ticker\n    df = df.sort_values(by=['ticker', 'date'])\n    \n    # Calculating previous day's close\n    df['pdc'] = df.groupby('ticker')['c'].shift(1)\n\n    # Calculating ranges and true range\n    df['high_low'] = df['h'] - df['l']\n    df['high_pdc'] = (df['h'] - df['pdc']).abs()\n    df['low_pdc'] = (df['l'] - df['pdc']).abs()\n    df['true_range'] = df[['high_low', 'high_pdc', 'low_pdc']].max(axis=1)\n    df['atr'] = df.groupby('ticker')['true_range'].transform(lambda x: x.rolling(window=14).mean())\n    \n    df['atr'] = df['atr'].shift(1)\n    \n    # df['atr'] = df['atr'].fillna(0)\n    # df['pdc'] = df['pdc'].fillna(0)\n    \n    df['d1_range'] = abs(df['h'] - df['l'])\n\n    # Shifting values for high, close, open, low, volume\n    for i in range(1, 4):\n        df[f'h{i}'] = df.groupby('ticker')['h'].shift(i).fillna(0)\n        # if i <= 2:  # Limiting to 2 days shift for close, open, low, volume\n        df[f'c{i}'] = df.groupby('ticker')['c'].shift(i).fillna(0)\n        df[f'o{i}'] = df.groupby('ticker')['o'].shift(i).fillna(0)\n        df[f'l{i}'] = df.groupby('ticker')['l'].shift(i).fillna(0)\n        df[f'v{i}'] = df.groupby('ticker')['v'].shift(i).fillna(0)\n\n    # Dollar volume calculations and shifts\n    df['dol_v'] = df['c'] * df['v']\n    df['dol_v1'] = df.groupby('ticker')['dol_v'].shift(1)\n    df['dol_v2'] = df.groupby('ticker')['dol_v'].shift(2)\n    df['dol_v3'] = df.groupby('ticker')['dol_v'].shift(3)\n    df['dol_v4'] = df.groupby('ticker')['dol_v'].shift(4)\n    df['dol_v5'] = df.groupby('ticker')['dol_v'].shift(5)\n\n    df['dol_v_cum5_1'] = df['dol_v1'] + df['dol_v2'] + df['dol_v3'] + df['dol_v3'] + df['dol_v5']\n\n    # Close range calculations and shifts\n    df['close_range'] = (df['c'] - df['l']) / (df['h'] - df['o'])\n    df['close_range1'] = df.groupby('ticker')['close_range'].shift(1)\n    df['close_range2'] = df.groupby('ticker')['close_range'].shift(2)\n\n    # Days Range\n    \n    df['range'] = (df['h'] - df['l'])\n    df['range1'] = df.groupby('ticker')['range'].shift(1)\n    df['range2'] = df.groupby('ticker')['range'].shift(2)\n\n    # Gap metrics related to ATR\n    df['gap_pct'] = (df['o'] / df['pdc']) - 1\n    df['gap_pct1'] = df.groupby('ticker')['gap_pct'].shift(1)\n    df['gap_pct2'] = df.groupby('ticker')['gap_pct'].shift(2)\n    df['gap_atr'] = ((df['o'] - df['pdc']) / df['atr'])\n    df['gap_atr1'] = ((df['o1'] - df['c2']) / df['atr'])\n    df['gap_atr2'] = ((df['o2'] - df['c3']) / df['atr'])\n    df['gap_pdh_atr'] = ((df['o'] - df['h1']) / df['atr'])\n\n    # High change metrics normalized by ATR\n    df['pct_chg'] = (df['c'] / df['c1']) - 1\n    df['high_pct_chg'] = (df['h'] / df['c1']) - 1\n    df['pct_chg1'] = df.groupby('ticker')['pct_chg'].shift(1)\n    df['high_pct_chg1'] = df.groupby('ticker')['high_pct_chg'].shift(1)\n    df['high_pct_chg2'] = df.groupby('ticker')['high_pct_chg'].shift(2)\n\n    df['high_chg'] = df['h'] - df['o']\n    df['high_chg1'] = df['h1'] - df['o1']\n    df['high_chg_atr'] = df['high_chg'] / df['atr']\n    df['high_chg_atr1'] = ((df['h1'] - df['o1']) / df['atr'])\n    df['high_chg_atr2'] = ((df['h2'] - df['o2']) / df['atr'])\n\n    # High change from previous day close normalized by ATR\n    df['high_chg_from_pdc_atr'] = ((df['h'] - df['c1']) / df['atr'])\n    df['high_chg_from_pdc_atr1'] = ((df['h1'] - df['c2']) / df['atr'])\n\n    # Percentage change in close price from the previous day\n    df['pct_change'] = ((df['c'] / df['c1'] - 1) * 100).round(2)\n\n    df['avg5_vol'] = df['v'].rolling(window=5).mean()\n    df['rvol'] = df['v'] / df['avg5_vol']\n    df['rvol1'] = df.groupby('ticker')['rvol'].shift(1)\n\n    # Calculating EMAs\n    for period in [9, 20, 50, 200]:\n        df[f'ema{period}'] = df.groupby('ticker')['c'].transform(lambda x: x.ewm(span=period, adjust=False).mean().fillna(0))\n        df[f'dist_h_{period}ema'] = df['h'] - df[f'ema{period}']\n        df[f'dist_h_{period}ema_atr'] = df[f'dist_h_{period}ema'] / df['atr']\n\n        df[f'dist_l_{period}ema'] = df['l'] - df[f'ema{period}']\n        df[f'dist_l_{period}ema_atr'] = df[f'dist_l_{period}ema'] / df['atr']\n\n        # Apply shifts to the calculated distances and normalize again by ATR\n        for dist in range(1, 5):\n            df[f'dist_h_{period}ema{dist}'] = df.groupby('ticker')[f'dist_h_{period}ema'].shift(dist)\n            df[f'dist_h_{period}ema_atr{dist}'] = df[f'dist_h_{period}ema{dist}'] / df['atr']\n\n            df[f'dist_l_{period}ema{dist}'] = df.groupby('ticker')[f'dist_l_{period}ema'].shift(dist)\n            df[f'dist_l_{period}ema_atr{dist}'] = df[f'dist_l_{period}ema{dist}'] / df['atr']\n\n    # Calculate rolling maximums and minimums\n    for window in [5, 20, 50, 100, 250]:\n        df[f'lowest_low_{window}'] = df.groupby('ticker')['l'].transform(lambda x: x.rolling(window=window, min_periods=1).min())\n        df[f'highest_high_{window}'] = df.groupby('ticker')['h'].transform(lambda x: x.rolling(window=window, min_periods=1).max())\n\n        # Shifting previous highs for selected windows\n        for dist in range(1, 5):\n            df[f'highest_high_{window}_{dist}'] = df.groupby('ticker')[f'highest_high_{window}'].shift(dist)\n\n    # Calculate rolling minimums for the low prices with shifts\n    df['lowest_low_30'] = df.groupby('ticker')['l'].transform(lambda x: x.rolling(window=30, min_periods=1).min())\n    df['lowest_low_30_1'] = df.groupby('ticker')['lowest_low_30'].shift(1)\n\n    # Calculate rolling maximums for high prices with multiple shifts\n    df['highest_high_100_1'] = df.groupby('ticker')['highest_high_100'].shift(1)\n    df['highest_high_100_4'] = df.groupby('ticker')['highest_high_100'].shift(4)\n    df['highest_high_250_1'] = df.groupby('ticker')['highest_high_250'].shift(1)\n    df['lowest_low_20_1'] = df.groupby('ticker')['lowest_low_20'].shift(1)\n    df['lowest_low_20_2'] = df.groupby('ticker')['lowest_low_20'].shift(2)\n    df['highest_high_20_1'] = df.groupby('ticker')['highest_high_20'].shift(1)\n    df['highest_high_20_2'] = df.groupby('ticker')['highest_high_20'].shift(2)\n    df['highest_high_5_1'] = df.groupby('ticker')['highest_high_5'].shift(1)\n\n    # Assuming l_ua is a predefined column in your DataFrame\n    df['lowest_low_20_ua'] = df.groupby('ticker')['l_ua'].transform(lambda x: x.rolling(window=20, min_periods=1).min())\n\n    # Calculate distances from the lowest lows normalized by ATR\n    df['h_dist_to_lowest_low_30'] = (df['h'] - df['lowest_low_30'])\n    df['h_dist_to_lowest_low_30_atr'] = (df['h'] - df['lowest_low_30']) / df['atr']\n    df['h_dist_to_lowest_low_20_atr'] = (df['h'] - df['lowest_low_20']) / df['atr']\n    df['h_dist_to_lowest_low_5_atr'] = (df['h'] - df['lowest_low_5']) / df['atr']\n    df['h_dist_to_highest_high_20_1_atr'] = (df['h'] - df['highest_high_20_1']) / df['atr']\n    df['h_dist_to_highest_high_20_2_atr'] = (df['h'] - df['highest_high_20_2']) / df['atr']\n    df['highest_high_5_dist_to_lowest_low_20_pct_1'] = (df['highest_high_5_1'] / df['lowest_low_20_1']) - 1\n    df['h_dist_to_lowest_low_20_pct'] = (df['h'] / df['lowest_low_20']) - 1\n\n    # Shifting EMAs\n    df['ema20_2'] = df.groupby('ticker')['ema20'].shift(2)\n    \n    df['ema9_1'] = df['ema9'].shift(1)\n    df['ema20_1'] = df['ema20'].shift(1)\n    df['ema50_1'] = df['ema50'].shift(1)\n\n    \n    # df['ema9_1'] = df['ema9_1'].fillna(0)\n    # df['ema20_1'] = df['ema20_1'].fillna(0)\n    # df['ema50_1'] = df['ema50_1'].fillna(0)\n\n\n    df['v_ua1'] = df.groupby('ticker')['v_ua'].shift(1)\n    df['v_ua2'] = df.groupby('ticker')['v_ua'].shift(2)\n    \n    df['c_ua1'] = df['c_ua'].shift(1)\n\n\n    # Drop intermediate columns\n    columns_to_drop = ['high_low', 'high_pdc', 'low_pdc']\n    df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n\n    return df\n\ndef calculate_trading_days(date):\n    # Define a range of trading days (30 days before and after the given date)\n    start_date = date - pd.Timedelta(days=30)\n    end_date = date + pd.Timedelta(days=30)\n\n    # Get the trading schedule for the range\n    schedule = nyse.schedule(start_date=start_date, end_date=end_date)\n    trading_days = schedule.index\n\n    # Ensure the date exists in the trading days\n    if date not in trading_days:\n        return pd.NaT, pd.NaT  # Return NaT if the date is not a trading day\n\n    # Find the location of the given date in the trading days\n    idx = trading_days.get_loc(date)\n\n    # Calculate the next trading day and the fourth previous trading day\n    date_plus_1 = trading_days[idx + 1] if idx + 1 < len(trading_days) else pd.NaT\n    date_minus_4 = trading_days[idx - 4] if idx - 4 >= 0 else pd.NaT\n\n    return date_plus_1, date_minus_4\ndef get_offsets(date):\n    if date not in trading_days_map:\n        return pd.NaT, pd.NaT\n    idx = trading_days_map[date]\n    date_plus_1 = trading_days_list[idx + 1] if idx + 1 < len(trading_days_list) else pd.NaT\n    date_minus_4 = trading_days_list[idx - 4] if idx - 4 >= 0 else pd.NaT\n    date_minus_30 = trading_days_list[idx - 30] if idx - 30 >= 0 else pd.NaT\n    return date_plus_1, date_minus_4, date_minus_30\n\n\n\n\n\ndef fetch_intraday_data(ticker, start_date, end_date):\n    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/30/minute/{start_date}/{end_date}?adjusted=true'\n    params = {'apiKey': API_KEY}\n    try:\n        response = requests.get(url, params=params)\n        if response.status_code == 200:\n            data = response.json()\n            if 'results' in data:\n                return pd.DataFrame(data['results'])\n            else:\n                print(f\"No results for {ticker}\")\n        else:\n            print(f\"Error fetching data for {ticker}: {response.status_code}\")\n    except Exception as e:\n        print(f\"Exception for {ticker}: {e}\")\n    return pd.DataFrame()\n\n\n\ndef process_lc_row(row):\n    \"\"\"Process a single row for intraday data and calculations.\"\"\"\n    try:\n        ticker = row['ticker']\n        date = row['date']\n\n        date_minus_4 = row['date_minus_4']\n        date_plus_1 = row['date_plus_1']\n\n        # Fetch and adjust intraday data\n        intraday_data = fetch_intraday_data(ticker, date_minus_4, date_plus_1)\n        intraday_data = adjust_intraday(intraday_data)\n\n        date_plus_1_formatted = datetime.datetime.strptime(date_plus_1, '%Y-%m-%d').date()\n\n        intraday_data_before = intraday_data[intraday_data['date'] != date_plus_1_formatted]\n        \n        resp_v = intraday_data_before[intraday_data_before['time_int'] == 900].set_index('date')['v_sum']\n        resp_o = intraday_data_before[intraday_data_before['time_int'] == 930].set_index('date')['o']\n        resp_v, resp_o = resp_v.align(resp_o, fill_value=0)\n        pm_dol_vol_all = resp_o * resp_v\n        avg_pm_dol_vol = pm_dol_vol_all.mean()\n\n        # Add results to row\n        row['avg_5d_pm_dol_vol'] = avg_pm_dol_vol\n        if avg_pm_dol_vol >= 10000000:\n            row['valid_pm_liq'] = 1\n        else:\n            row['valid_pm_liq'] = 0\n        # row['valid_pm_liq'] = 1 if avg_pm_dol_vol >= 10000000 else 0\n\n        \n        intraday_data_after = intraday_data[intraday_data['date'] == date_plus_1_formatted]      \n                    \n\n        pm_df = intraday_data_after[intraday_data_after['time_int'] <= 900].set_index('time')\n        open_df = intraday_data_after[intraday_data_after['time_int'] <= 930].set_index('time')\n\n        if not pm_df.empty:\n            resp_v = pm_df['v_sum'][-1]\n            resp_o = open_df['o'][-1]\n            pm_dol_vol_next_day = resp_o * resp_v\n            pmh_next_day = pm_df['hod_all'][-1]\n        else:\n            pm_dol_vol_next_day = 0\n            pmh_next_day = 0\n            resp_o = 0\n        \n        row['pmh_next_day'] = pmh_next_day\n        row['open_next_day'] = resp_o\n        row['pm_dol_vol_next_day'] = pm_dol_vol_next_day\n\n    except Exception as e:\n        print(f\"Error processing LC Row {row['ticker']} on {row['date']}: {e}\")\n        row['avg_5d_pm_dol_vol'] = None\n        row['valid_pm_liq'] = None\n        row['pmh_next_day'] = 0\n        row['open_next_day'] = 0\n        row['pm_dol_vol_next_day'] = 0\n\n    return row\n\n\ndef dates_before_after(df):\n    global trading_days_map, trading_days_list\n\n    start_date = df['date'].min() - pd.Timedelta(days=60)\n    end_date = df['date'].max() + pd.Timedelta(days=30)\n    schedule = nyse.schedule(start_date=start_date, end_date=end_date)\n    trading_days = pd.Series(schedule.index, index=schedule.index)\n\n    # Map trading days for faster lookup\n    trading_days_list = trading_days.index.to_list()\n    trading_days_map = {day: idx for idx, day in enumerate(trading_days_list)}\n\n    results = df_lc['date'].map(get_offsets)\n    df_lc[['date_plus_1', 'date_minus_4', 'date_minus_30']] = pd.DataFrame(results.tolist(), index=df_lc.index)\n\n    # Format dates as strings if needed\n    df_lc['date_plus_1'] = df_lc['date_plus_1'].dt.strftime('%Y-%m-%d')\n    df_lc['date_minus_4'] = df_lc['date_minus_4'].dt.strftime('%Y-%m-%d')\n    df_lc['date_minus_30'] = df_lc['date_minus_30'].dt.strftime('%Y-%m-%d')\n\n\n    return df\n\n\ndef check_next_day_valid_lc(df):\n    # Ensure minimum price columns exist for each check column\n\n    columns_to_check = ['lc_backside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',\n     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']\n    \n    for col in columns_to_check:\n        min_price_col = col + '_min_price'\n        if col in df.columns and min_price_col in df.columns:\n            # Vectorized condition checks\n            condition = (df[col] == 1) & (df['open_next_day'] >= df[min_price_col])\n            df[col] = condition.astype(int)  # Update the column based on conditions\n\n    df = df[~(df[columns_to_check] == 0).all(axis=1)]\n\n    return df\n\n\ndef check_lc_pm_liquidity(df):\n    df.loc[\n        ((df['lc_frontside_d3_extended_1'] == 1) | (df['lc_backside_d3_extended_1'] == 1) | (df['lc_frontside_d3_extended_2'] == 1) | (df['lc_backside_d3_extended_2'] == 1) | (df['lc_frontside_d4_para'] == 1) | (df['lc_backside_d4_para'] == 1) | \n         (df['lc_frontside_d3_uptrend'] == 1) | (df['lc_backside_d3'] == 1) | (df['lc_frontside_d2_uptrend'] == 1) | (df['lc_fbo'] == 1)) & \n        (df['valid_pm_liq'] != 1),\n        ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para', \n        'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_fbo']\n        ] = 0\n    \n    df.loc[\n        ((df['lc_frontside_d2'] == 1) | (df['lc_backside_d2'] == 1)) & \n        (df['valid_pm_liq'] == 0),\n        ['lc_frontside_d2', 'lc_backside_d2']\n        ] = 0\n    \n\n\n    columns_to_check = ['lc_frontside_d3_extended_1', 'lc_backside_d3_extended_1', 'lc_frontside_d3_extended_2', 'lc_backside_d3_extended_2', 'lc_frontside_d4_para', 'lc_backside_d4_para',\n     'lc_frontside_d3_uptrend', 'lc_backside_d3', 'lc_frontside_d2_uptrend', 'lc_frontside_d2', 'lc_backside_d2', 'lc_fbo']\n    \n    # Drop rows where all specified columns are 0\n    df = df[~(df[columns_to_check] == 0).all(axis=1)]\n    \n    # df_lc = df_lc[df_lc['valid_pm_liq'] == 1]\n\n    return df\n\ndef process_dataframe(func, data):\n    with ProcessPoolExecutor(max_workers=cpu_count()) as executor:\n        processed_rows = list(executor.map(func, data))\n    return pd.DataFrame(processed_rows)\n\n\nasync def main():\n    global df_lc, df_sc\n    ### Get Main List\n    all_results = []\n    adj = \"true\"\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_intial_stock_list(session, date, adj) for date in DATES]\n        # results = await asyncio.gather(*tasks)\n        # all_results = [result for result in results if result is not None]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        # all_results = [result for result in results if isinstance(result, pd.DataFrame)]\n\n\n        all_results = []\n        retry_tasks = []\n\n        # Check results and prepare for retry if necessary\n        for i, result in enumerate(results):\n            if isinstance(result, Exception):\n                # print(f\"Retrying failed task for date: {DATES[i]} due to {result}\")\n                retry_tasks.append(fetch_intial_stock_list(session, DATES[i], adj))\n            else:\n                all_results.append(result)\n\n        # Retry failed tasks\n        if retry_tasks:\n            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)\n            # Merge retry results, assuming they are in the same order as retry_tasks\n            for retry_result in retry_results:\n                if not isinstance(retry_result, Exception):\n                    all_results.append(retry_result)\n                else:\n                    print(f\"Failed after retry: {retry_result}\")\n\n\n\n    df_a = pd.concat(all_results, ignore_index=True)\n    all_results = []\n    adj = \"false\"\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_intial_stock_list(session, date, adj) for date in DATES]\n        # results = await asyncio.gather(*tasks)\n        # all_results = [result for result in results if result is not None]\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        # all_results = [result for result in results if isinstance(result, pd.DataFrame)]\n\n        \n        all_results = []\n        retry_tasks = []\n\n        # Check results and prepare for retry if necessary\n        for i, result in enumerate(results):\n            if isinstance(result, Exception):\n                # print(f\"Retrying failed task for date: {DATES[i]} due to {result}\")\n                retry_tasks.append(fetch_intial_stock_list(session, DATES[i], adj))\n            else:\n                all_results.append(result)\n\n        # Retry failed tasks\n        if retry_tasks:\n            retry_results = await asyncio.gather(*retry_tasks, return_exceptions=True)\n            # Merge retry results, assuming they are in the same order as retry_tasks\n            for retry_result in retry_results:\n                if not isinstance(retry_result, Exception):\n                    all_results.append(retry_result)\n                else:\n                    print(f\"Failed after retry: {retry_result}\")\n\n\n    df_ua = pd.concat(all_results, ignore_index=True)\n    df_ua.rename(columns={col: col + '_ua' if col not in ['date', 'ticker'] else col for col in df_ua.columns}, inplace=True)\n\n    \n\n    print(\"done 1\")\n\n    df = pd.merge(df_a, df_ua, on=['date', 'ticker'], how='inner')\n    \n    df = df.drop(columns=['vw', 't', 'n', 'vw_ua', 't_ua', 'n_ua'])\n    df = df.sort_values(by='date')\n\n    df['date'] = pd.to_datetime(df['date'])\n\n    print(df)\n    print(\"done 2\")\n\n    \n\n    df = df.select_dtypes(include=['floating']).round(2).join(df.select_dtypes(exclude=['floating']))\n\n\n\n    df = compute_indicators1(df)\n    df = df.sort_values(by='date')\n    # df = df[df['pre_conditions'] == True]\n\n    \n\n    df = df.select_dtypes(include=['floating']).round(2).join(df.select_dtypes(exclude=['floating']))\n\n\n\n    # df = df[(df['date'] >= START_DATE_DT) & (df['date'] <= END_DATE_DT)]\n    # df = df.reset_index(drop=True)\n\n    print(df)\n    print(\"done 3\")\n\n\n    df_lc = check_high_lvl_filter_lc(df)\n\n    '''\n\n    df = dates_before_after(df)\n\n    print(\"done 4\")\n\n    \n    # df = df[(df['date'] >= start_date_70_days_before) & (df['date'] <= END_DATE_DT)]\n    # df = df.reset_index(drop=True)\n\n\n\n    rows_lc = df_lc.to_dict(orient='records')\n\n    # Use ProcessPoolExecutor to process both dataframes concurrently\n    with ProcessPoolExecutor() as executor:\n        future_lc = executor.submit(process_dataframe, process_lc_row, rows_lc)\n\n        df_lc = future_lc.result()\n\n    print(\"done 5\")\n\n    # Continue with further processing\n    df_lc = (df_lc)\n    df_lc = check_next_day_valid_lc(df_lc)\n    #'''\n\n    df_lc = filter_lc_rows(df_lc)\n\n    print(\"done 6\")\n    \n\n\n\n    df_lc = df_lc[(df_lc['date'] >= START_DATE_DT) & (df_lc['date'] <= END_DATE_DT)]\n    df_lc = df_lc.reset_index(drop=True)\n\n\n\n    # Output the final dataframes\n    # print(df_lc)\n    print(df_lc[['date', 'ticker']])\n    df_lc.to_csv(\"lc_backtest.csv\")\n\n\n\n\n        \n\n\n        \nif __name__ == \"__main__\":\n    START_DATE = '2024-01-01'  # Specify the start date\n    END_DATE = '2025-10-20'  \n\n    START_DATE_DT = pd.to_datetime(START_DATE)\n    END_DATE_DT = pd.to_datetime(END_DATE)\n\n    start_date_70_days_before = pd.Timestamp(START_DATE) - pd.DateOffset(days=70)\n    start_date_70_days_before = pd.to_datetime(start_date_70_days_before)\n\n    start_date_300_days_before = pd.Timestamp(START_DATE) - pd.DateOffset(days=400)\n    start_date_300_days_before = str(start_date_300_days_before)[:10]\n                                                                          \n    schedule = nyse.schedule(start_date=start_date_300_days_before, end_date=END_DATE)\n    DATES = nyse.valid_days(start_date=start_date_300_days_before, end_date=END_DATE)\n    DATES = [date.strftime('%Y-%m-%d') for date in nyse.valid_days(start_date=start_date_300_days_before, end_date=END_DATE)]\n\n\n    asyncio.run(main())\n    # asyncio.run(main())\n\n    print(\"Getting Stocks\")\n\n\n\n",
  "filename": "lc d2 scan - oct 25 new ideas (2).py"
}