{
  "data": [
    {
      "id": "1765160187567",
      "name": "backside para b copy Scanner",
      "title": "backside para b copy Scanner",
      "type": "Trading Scanner",
      "scanner_type": "uploaded",
      "functionName": "scan_symbol",
      "enhanced": true,
      "code": "# daily_para_backside_lite_scan.py\n# Daily-only \"A+ para, backside\" scan — lite mold.\n# Trigger: D-1 (or D-2) fits; trade day (D0) must gap & open > D-1 high.\n# D-1 must take out D-2 high and close above D-2 close.\n# Adds absolute D-1 volume floor: d1_volume_min.\n\nimport pandas as pd, numpy as np, requests\nfrom datetime import datetime\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# ───────── config ─────────\nsession  = requests.Session()\nAPI_KEY  = \"Fm7brz4s23eSocDErnL68cE7wspz2K1I\"\nBASE_URL = \"https://api.polygon.io\"\nMAX_WORKERS = 6\n\nPRINT_FROM = \"2025-01-01\"  # set None to keep all\nPRINT_TO   = None\n\n# ───────── knobs ─────────\nP = {\n    # hard liquidity / price\n    \"price_min\"        : 8.0,\n    \"adv20_min_usd\"    : 30_000_000,\n\n    # backside context (absolute window)\n    \"abs_lookback_days\": 1000,\n    \"abs_exclude_days\" : 10,\n    \"pos_abs_max\"      : 0.75,\n\n    # trigger mold (evaluated on D-1 or D-2)\n    \"trigger_mode\"     : \"D1_or_D2\",   # \"D1_only\" or \"D1_or_D2\"\n    \"atr_mult\"         : .9,\n    \"vol_mult\"         : 0.9,         # max(D-1 vol/avg, D-2 vol/avg)\n\n    # Relative D-1 vol (optional). Set to None to disable.\n    \"d1_vol_mult_min\"  : None,         # e.g., 1.25\n\n    # NEW: Absolute D-1 volume floor (shares). Set None to disable.\n    \"d1_volume_min\"    : 15_000_000,   # e.g., require ≥ 20M shares on D-1\n\n    \"slope5d_min\"      : 3.0,\n    \"high_ema9_mult\"   : 1.05,\n\n    # trade-day (D0) gates\n    \"gap_div_atr_min\"   : .75,\n    \"open_over_ema9_min\": .9,\n    \"d1_green_atr_min\"  : 0.30,\n    \"require_open_gt_prev_high\": True,\n\n    # relative requirement\n    \"enforce_d1_above_d2\": True,\n}\n\n# ───────── universe ─────────\nSYMBOLS = [\n    'MSTR','SMCI','DJT','BABA','TCOM','AMC','SOXL','MRVL','TGT','DOCU','ZM','DIS',\n    'NFLX','SNAP','RBLX','META','SE','NVDA','AAPL','MSFT','GOOGL','AMZN','TSLA',\n    'AMD','INTC','BA','PYPL','QCOM','ORCL','KO','PEP','ABBV','JNJ','CRM','BAC',\n    'JPM','WMT','CVX','XOM','COP','RTX','SPGI','GS','HD','LOW','COST','UNH','NKE',\n    'LMT','HON','CAT','LIN','ADBE','AVGO','TXN','ACN','UPS','BLK','PM','ELV','VRTX',\n    'ZTS','NOW','ISRG','PLD','MS','MDT','WM','GE','IBM','BKNG','FDX','ADP','EQIX',\n    'DHR','SNPS','REGN','SYK','TMO','CVS','INTU','SCHW','CI','APD','SO','MMC','ICE',\n    'FIS','ADI','CSX','LRCX','GILD','RIVN','PLTR','SNOW','SPY','QQQ','IWM','RIOT',\n    'MARA','COIN','MRNA','CELH','UPST','AFRM','DKNG'\n]\n\n# ───────── fetch ─────────\ndef fetch_daily(tkr: str, start: str, end: str) -> pd.DataFrame:\n    url = f\"{BASE_URL}/v2/aggs/ticker/{tkr}/range/1/day/{start}/{end}\"\n    r   = session.get(url, params={\"apiKey\": API_KEY, \"adjusted\":\"true\", \"sort\":\"asc\", \"limit\":50000})\n    r.raise_for_status()\n    rows = r.json().get(\"results\", [])\n    if not rows: return pd.DataFrame()\n    return (pd.DataFrame(rows)\n            .assign(Date=lambda d: pd.to_datetime(d[\"t\"], unit=\"ms\", utc=True))\n            .rename(columns={\"o\":\"Open\",\"h\":\"High\",\"l\":\"Low\",\"c\":\"Close\",\"v\":\"Volume\"})\n            .set_index(\"Date\")[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n            .sort_index())\n\n# ───────── metrics (lite) ─────────\ndef add_daily_metrics(df: pd.DataFrame) -> pd.DataFrame:\n    if df.empty: return df\n    m = df.copy()\n    try: m.index = m.index.tz_localize(None)\n    except Exception: pass\n\n    m[\"EMA_9\"]  = m[\"Close\"].ewm(span=9 , adjust=False).mean()\n    m[\"EMA_20\"] = m[\"Close\"].ewm(span=20, adjust=False).mean()\n\n    hi_lo   = m[\"High\"] - m[\"Low\"]\n    hi_prev = (m[\"High\"] - m[\"Close\"].shift(1)).abs()\n    lo_prev = (m[\"Low\"]  - m[\"Close\"].shift(1)).abs()\n    m[\"TR\"]      = pd.concat([hi_lo, hi_prev, lo_prev], axis=1).max(axis=1)\n    m[\"ATR_raw\"] = m[\"TR\"].rolling(14, min_periods=14).mean()\n    m[\"ATR\"]     = m[\"ATR_raw\"].shift(1)\n\n    m[\"VOL_AVG\"]     = m[\"Volume\"].rolling(14, min_periods=14).mean().shift(1)\n    m[\"Prev_Volume\"] = m[\"Volume\"].shift(1)\n    m[\"ADV20_$\"]     = (m[\"Close\"] * m[\"Volume\"]).rolling(20, min_periods=20).mean().shift(1)\n\n    m[\"Slope_9_5d\"]  = (m[\"EMA_9\"] - m[\"EMA_9\"].shift(5)) / m[\"EMA_9\"].shift(5) * 100\n    m[\"High_over_EMA9_div_ATR\"] = (m[\"High\"] - m[\"EMA_9\"]) / m[\"ATR\"]\n\n    m[\"Gap_abs\"]       = (m[\"Open\"] - m[\"Close\"].shift(1)).abs()\n    m[\"Gap_over_ATR\"]  = m[\"Gap_abs\"] / m[\"ATR\"]\n    m[\"Open_over_EMA9\"]= m[\"Open\"] / m[\"EMA_9\"]\n\n    m[\"Body_over_ATR\"] = (m[\"Close\"] - m[\"Open\"]) / m[\"ATR\"]\n\n    m[\"Prev_Close\"] = m[\"Close\"].shift(1)\n    m[\"Prev_Open\"]  = m[\"Open\"].shift(1)\n    m[\"Prev_High\"]  = m[\"High\"].shift(1)\n    return m\n\n# ───────── helpers ─────────\ndef abs_top_window(df: pd.DataFrame, d0: pd.Timestamp, lookback_days: int, exclude_days: int):\n    if df.empty: return (np.nan, np.nan)\n    cutoff = d0 - pd.Timedelta(days=exclude_days)\n    wstart = cutoff - pd.Timedelta(days=lookback_days)\n    win = df[(df.index > wstart) & (df.index <= cutoff)]\n    if win.empty: return (np.nan, np.nan)\n    return float(win[\"Low\"].min()), float(win[\"High\"].max())\n\ndef pos_between(val, lo, hi):\n    if any(pd.isna(t) for t in (val, lo, hi)) or hi <= lo: return np.nan\n    return max(0.0, min(1.0, float((val - lo) / (hi - lo))))\n\ndef _mold_on_row(rx: pd.Series) -> bool:\n    if pd.isna(rx.get(\"Prev_Close\")) or pd.isna(rx.get(\"ADV20_$\")):\n        return False\n    if rx[\"Prev_Close\"] < P[\"price_min\"] or rx[\"ADV20_$\"] < P[\"adv20_min_usd\"]:\n        return False\n    vol_avg = rx[\"VOL_AVG\"]\n    if pd.isna(vol_avg) or vol_avg <= 0: return False\n    vol_sig = max(rx[\"Volume\"]/vol_avg, rx[\"Prev_Volume\"]/vol_avg)\n    checks = [\n        (rx[\"TR\"] / rx[\"ATR\"]) >= P[\"atr_mult\"],\n        vol_sig                 >= P[\"vol_mult\"],\n        rx[\"Slope_9_5d\"]        >= P[\"slope5d_min\"],\n        rx[\"High_over_EMA9_div_ATR\"] >= P[\"high_ema9_mult\"],\n    ]\n    return all(bool(x) and np.isfinite(x) for x in checks)\n\n# ───────── scan one symbol ─────────\ndef scan_symbol(sym: str, start: str, end: str) -> pd.DataFrame:\n    df = fetch_daily(sym, start, end)\n    if df.empty: return pd.DataFrame()\n    m  = add_daily_metrics(df)\n\n    rows = []\n    for i in range(2, len(m)):\n        d0 = m.index[i]\n        r0 = m.iloc[i]       # D0\n        r1 = m.iloc[i-1]     # D-1\n        r2 = m.iloc[i-2]     # D-2\n\n        # Backside vs D-1 close\n        lo_abs, hi_abs = abs_top_window(m, d0, P[\"abs_lookback_days\"], P[\"abs_exclude_days\"])\n        pos_abs_prev = pos_between(r1[\"Close\"], lo_abs, hi_abs)\n        if not (pd.notna(pos_abs_prev) and pos_abs_prev <= P[\"pos_abs_max\"]):\n            continue\n\n        # Choose trigger\n        trigger_ok = False; trig_row = None; trig_tag = \"-\"\n        if P[\"trigger_mode\"] == \"D1_only\":\n            if _mold_on_row(r1): trigger_ok, trig_row, trig_tag = True, r1, \"D-1\"\n        else:\n            if _mold_on_row(r1): trigger_ok, trig_row, trig_tag = True, r1, \"D-1\"\n            elif _mold_on_row(r2): trigger_ok, trig_row, trig_tag = True, r2, \"D-2\"\n        if not trigger_ok:\n            continue\n\n        # D-1 must be green\n        if not (pd.notna(r1[\"Body_over_ATR\"]) and r1[\"Body_over_ATR\"] >= P[\"d1_green_atr_min\"]):\n            continue\n\n        # Absolute D-1 volume floor (shares)\n        if P[\"d1_volume_min\"] is not None:\n            if not (pd.notna(r1[\"Volume\"]) and r1[\"Volume\"] >= P[\"d1_volume_min\"]):\n                continue\n\n        # Optional relative D-1 vol multiple\n        if P[\"d1_vol_mult_min\"] is not None:\n            if not (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"] > 0 and (r1[\"Volume\"]/r1[\"VOL_AVG\"]) >= P[\"d1_vol_mult_min\"]):\n                continue\n\n        # D-1 > D-2 highs & close\n        if P[\"enforce_d1_above_d2\"]:\n            if not (pd.notna(r1[\"High\"]) and pd.notna(r2[\"High\"]) and r1[\"High\"] > r2[\"High\"]\n                    and pd.notna(r1[\"Close\"]) and pd.notna(r2[\"Close\"]) and r1[\"Close\"] > r2[\"Close\"]):\n                continue\n\n        # D0 gates\n        if pd.isna(r0[\"Gap_over_ATR\"]) or r0[\"Gap_over_ATR\"] < P[\"gap_div_atr_min\"]:\n            continue\n        if P[\"require_open_gt_prev_high\"] and not (r0[\"Open\"] > r1[\"High\"]):\n            continue\n        if pd.isna(r0[\"Open_over_EMA9\"]) or r0[\"Open_over_EMA9\"] < P[\"open_over_ema9_min\"]:\n            continue\n\n        d1_vol_mult = (r1[\"Volume\"]/r1[\"VOL_AVG\"]) if (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"]>0) else np.nan\n        volsig_max  = (max(r1[\"Volume\"]/r1[\"VOL_AVG\"], r2[\"Volume\"]/r2[\"VOL_AVG\"])\n                       if (pd.notna(r1[\"VOL_AVG\"]) and r1[\"VOL_AVG\"]>0 and pd.notna(r2[\"VOL_AVG\"]) and r2[\"VOL_AVG\"]>0)\n                       else np.nan)\n\n        rows.append({\n            \"Ticker\": sym,\n            \"Date\": d0.strftime(\"%Y-%m-%d\"),\n            \"Trigger\": trig_tag,\n            \"PosAbs_1000d\": round(float(pos_abs_prev), 3),\n            \"D1_Body/ATR\": round(float(r1[\"Body_over_ATR\"]), 2),\n            \"D1Vol(shares)\": int(r1[\"Volume\"]) if pd.notna(r1[\"Volume\"]) else np.nan,   # absolute volume\n            \"D1Vol/Avg\": round(float(d1_vol_mult), 2) if pd.notna(d1_vol_mult) else np.nan,\n            \"VolSig(max D-1,D-2)/Avg\": round(float(volsig_max), 2) if pd.notna(volsig_max) else np.nan,\n            \"Gap/ATR\": round(float(r0[\"Gap_over_ATR\"]), 2),\n            \"Open>PrevHigh\": bool(r0[\"Open\"] > r1[\"High\"]),\n            \"Open/EMA9\": round(float(r0[\"Open_over_EMA9\"]), 2),\n            \"D1>H(D-2)\": bool(r1[\"High\"] > r2[\"High\"]),\n            \"D1Close>D2Close\": bool(r1[\"Close\"] > r2[\"Close\"]),\n            \"Slope9_5d\": round(float(r0[\"Slope_9_5d\"]), 2) if pd.notna(r0[\"Slope_9_5d\"]) else np.nan,\n            \"High-EMA9/ATR(trigger)\": round(float(trig_row[\"High_over_EMA9_div_ATR\"]), 2),\n            \"ADV20_$\": round(float(r0[\"ADV20_$\"])) if pd.notna(r0[\"ADV20_$\"]) else np.nan,\n        })\n\n    return pd.DataFrame(rows)\n\n# ───────── main ─────────\nif __name__ == \"__main__\":\n    fetch_start = \"2021-01-01\"\n    fetch_end   = datetime.today().strftime(\"%Y-%m-%d\")\n\n    results = []\n    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:\n        futs = {exe.submit(scan_symbol, s, fetch_start, fetch_end): s for s in SYMBOLS}\n        for fut in as_completed(futs):\n            df = fut.result()\n            if df is not None and not df.empty:\n                results.append(df)\n\n    if results:\n        out = pd.concat(results, ignore_index=True)\n        if PRINT_FROM:\n            out = out[pd.to_datetime(out[\"Date\"]) >= pd.to_datetime(PRINT_FROM)]\n        if PRINT_TO:\n            out = out[pd.to_datetime(out[\"Date\"]) <= pd.to_datetime(PRINT_TO)]\n        out = out.sort_values([\"Date\",\"Ticker\"], ascending=[False, True])\n        pd.set_option(\"display.max_columns\", None, \"display.width\", 0)\n        print(\"\\nBackside A+ (lite) — trade-day hits:\\n\")\n        print(out.to_string(index=False))\n    else:\n        print(\"No hits. Consider relaxing high_ema9_mult / gap_div_atr_min / d1_volume_min.\")",
      "description": "Working Backside B scanner with proper date range logic",
      "createdAt": "2025-12-08T02:16:27.567Z",
      "updatedAt": "2025-12-08T02:16:27.567Z",
      "status": "active",
      "scannerCount": 1,
      "aggregation_method": "single",
      "tags": [
        "scanner",
        "python",
        "trading",
        "backside",
        "technical-analysis"
      ],
      "features": {
        "hasParameters": true,
        "hasMarketData": true,
        "hasEnhancedFormatting": false
      }
    }
  ],
  "timestamp": "2025-12-08T02:16:27.569Z",
  "count": 1
}